model_family: llama3-8b
model_path: results/tofu/llama3-8b/forget01/FINETUNE/seed_1001/epoch5_1e-05_FixRef_maskTrue_1.0_1.0/1/unlearn_times_1/checkpoint-last
use_LoRA: false
LoRA:
  r: 8
  alpha: 32
  dropout: 0.05
forget_data: tofu
data_path: data/tofu
split: forget01
task_id: 1
forget_loss: GA1+GD3
lr: 1.0e-05
num_epochs: 2
batch_size: 2
gradient_accumulation_steps: 4
forget_coeff: 1.0
regularization_coeff: 1.0
beta: 0.1
weight_decay: 0.01
fix_ref_model: ''
mask: true
seed: 1001
save_checkpoint: false
overwrite_dir: false
save_steps: last
save_root: results/5
save_dir: ${save_root}/${model_family}/${split}/${forget_loss}/seed_${seed}/epoch${num_epochs}_${lr}_FixRef${fix_ref_model}_mask${mask}_${forget_coeff}_${regularization_coeff}
ds_size: 300
eval_unlearn_step: last
eval:
  model_family: ${..model_family}
  forget_loss: ${..forget_loss}
  do_sample: false
  data_path:
  - data/tofu
  - data/tofu
  - data/tofu
  - data/tofu
  split: ${..split}_perturbed
  split_list:
  - retain_perturbed
  - real_authors_perturbed
  - world_facts_perturbed
  - ${split}_perturbed
  eval_task:
  - eval_log
  - eval_real_author_wo_options
  - eval_real_world_wo_options
  - eval_log_forget
  question_key:
  - question
  - question
  - question
  - question
  answer_key:
  - answer
  - answer
  - answer
  - answer
  base_answer_key:
  - paraphrased_answer
  - answer
  - answer
  - paraphrased_answer
  perturbed_answer_key:
  - perturbed_answer
  - perturbed_answer
  - perturbed_answer
  - perturbed_answer
  generation:
    max_length: 1024
    max_new_tokens: null
  save_generated_text: true
  ds_size: ${..ds_size}
  overwrite: true
  use_pretrained: false
  batch_size: 5
