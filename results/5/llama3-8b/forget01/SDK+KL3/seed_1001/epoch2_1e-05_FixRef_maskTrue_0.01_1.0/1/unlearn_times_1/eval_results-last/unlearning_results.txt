Real Authors ROUGE: 0.7568333333333334
Real Authors Probability: 0.6225138865617493
Real Authors Truth Ratio: 0.9102375831328864
Real Authors Token Entropy: 0.9707132693144496
Real Authors Cosine Similarity: 0.816907685175538
Real Authors Entailment Score: 0.71
Real World ROUGE: 0.8383333333333333
Real World Probability: 0.26043750702172763
Real World Truth Ratio: 0.6312883611083548
Real World Token Entropy: 0.9199706759603188
Real World Cosine Similarity: 0.6652091646566987
Real World Entailment Score: 0.7
Retain ROUGE: 0.4843484259340681
Retain Probability: 0.986505024617637
Retain Truth Ratio: 0.4339395358772353
Retain Token Entropy: 0.9122532820075803
Retain Cosine Similarity: 0.7733006662378709
Retain Entailment Score: 0.33
Forget ROUGE: 0.46539069005761197
Forget Probability: 0.4315399794753271
Forget Truth Ratio: 0.9107606397174809
Forget Token Entropy: 0.8675305808314192
Forget Cosine Similarity: 0.7567006755620241
Forget Entailment Score: 0.375
Model Utility Retain: 0.5554308202750043
Model Utility: 0.617984991958047
Forget Efficacy: 0.4121216030375112
split: forget01
forget_loss: SDK+KL3
forget_coeff: 0.01
regularization_coeff: 1.0
learning_rate: 1e-05
epochs: 2
fix_ref_model: 
mask: True
unlearn_step: last
task_id: 1
unlearn_times: 1
