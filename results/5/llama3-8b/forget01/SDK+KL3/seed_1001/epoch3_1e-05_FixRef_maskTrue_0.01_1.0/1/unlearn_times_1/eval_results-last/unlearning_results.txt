Real Authors ROUGE: 0.6728333333333333
Real Authors Probability: 0.6390241240319559
Real Authors Truth Ratio: 0.9116336497559888
Real Authors Token Entropy: 0.8562614790996983
Real Authors Cosine Similarity: 0.6879080479964614
Real Authors Entailment Score: 0.66
Real World ROUGE: 0.7366666666666666
Real World Probability: 0.2781045512737583
Real World Truth Ratio: 0.6251033818731928
Real World Token Entropy: 0.8300639864622609
Real World Cosine Similarity: 0.5679963215254247
Real World Entailment Score: 0.56
Retain ROUGE: 0.054923298182026015
Retain Probability: 0.9841909818028414
Retain Truth Ratio: 0.4309076626655762
Retain Token Entropy: 0.11767131870972439
Retain Cosine Similarity: 0.17057326884629825
Retain Entailment Score: 0.043333333333333335
Forget ROUGE: 0.03164634146341463
Forget Probability: 0.44578755141184123
Forget Truth Ratio: 0.9083905788552291
Forget Token Entropy: 0.07293989966997073
Forget Cosine Similarity: 0.13586080456152558
Forget Entailment Score: 0.0
Model Utility Retain: 0.10172645166619393
Model Utility: 0.22909370952224056
Forget Efficacy: 0.695662944741598
split: forget01
forget_loss: SDK+KL3
forget_coeff: 0.01
regularization_coeff: 1.0
learning_rate: 1e-05
epochs: 3
fix_ref_model: 
mask: True
unlearn_step: last
task_id: 1
unlearn_times: 1
