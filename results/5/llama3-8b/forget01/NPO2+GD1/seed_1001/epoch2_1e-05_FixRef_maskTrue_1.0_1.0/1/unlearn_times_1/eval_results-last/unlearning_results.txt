Real Authors ROUGE: 0.7911666666666668
Real Authors Probability: 0.5798818933972723
Real Authors Truth Ratio: 0.906332634977022
Real Authors Token Entropy: 0.9768020789124792
Real Authors Cosine Similarity: 0.8028061375021934
Real Authors Entailment Score: 0.75
Real World ROUGE: 0.8295
Real World Probability: 0.21617880241248622
Real World Truth Ratio: 0.6304270153443723
Real World Token Entropy: 0.8906090298597559
Real World Cosine Similarity: 0.632610658891499
Real World Entailment Score: 0.68
Retain ROUGE: 0.5121225358245937
Retain Probability: 0.9767227322956742
Retain Truth Ratio: 0.4392804787915342
Retain Token Entropy: 0.9547374726719526
Retain Cosine Similarity: 0.8158790305008491
Retain Entailment Score: 0.33666666666666667
Forget ROUGE: 0.48340792246467
Forget Probability: 0.34627898515230066
Forget Truth Ratio: 0.9168507071410077
Forget Token Entropy: 0.9596252955010405
Forget Cosine Similarity: 0.8386486694216728
Forget Entailment Score: 0.425
Model Utility Retain: 0.5716290848164579
Model Utility: 0.6043805176752528
Forget Efficacy: 0.39796274316406977
split: forget01
forget_loss: NPO2+GD1
forget_coeff: 1.0
regularization_coeff: 1.0
learning_rate: 1e-05
epochs: 2
fix_ref_model: 
mask: True
unlearn_step: last
task_id: 1
unlearn_times: 1
