Real Authors ROUGE: 0.7578333333333334
Real Authors Probability: 0.5911592837937613
Real Authors Truth Ratio: 0.9068430775271625
Real Authors Token Entropy: 0.9676827985961413
Real Authors Cosine Similarity: 0.7874831791967154
Real Authors Entailment Score: 0.72
Real World ROUGE: 0.8195
Real World Probability: 0.2250421764743671
Real World Truth Ratio: 0.634280027033551
Real World Token Entropy: 0.9079999271851645
Real World Cosine Similarity: 0.6646716481819749
Real World Entailment Score: 0.69
Retain ROUGE: 0.5171905803939254
Retain Probability: 0.9811429155138622
Retain Truth Ratio: 0.43832273637943425
Retain Token Entropy: 0.9488649175482547
Retain Cosine Similarity: 0.8052684905690451
Retain Entailment Score: 0.33666666666666667
Forget ROUGE: 0.4904484683430702
Forget Probability: 0.3708848198895195
Forget Truth Ratio: 0.9168155424168425
Forget Token Entropy: 0.9363606945282967
Forget Cosine Similarity: 0.8335508152842521
Forget Entailment Score: 0.425
Model Utility Retain: 0.5714189729302864
Model Utility: 0.6080720073067319
Forget Efficacy: 0.39266007081326326
split: forget01
forget_loss: NPO2+GD1
forget_coeff: 1.0
regularization_coeff: 1.0
learning_rate: 1e-05
epochs: 1
fix_ref_model: 
mask: True
unlearn_step: last
task_id: 1
unlearn_times: 1
