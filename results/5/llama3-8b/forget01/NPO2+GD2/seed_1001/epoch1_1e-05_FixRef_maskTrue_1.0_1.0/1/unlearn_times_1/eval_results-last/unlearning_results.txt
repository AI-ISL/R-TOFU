Real Authors ROUGE: 0.8015000000000001
Real Authors Probability: 0.5927243191937539
Real Authors Truth Ratio: 0.9071709112434693
Real Authors Token Entropy: 0.9749899976271581
Real Authors Cosine Similarity: 0.8103242706507444
Real Authors Entailment Score: 0.75
Real World ROUGE: 0.8225
Real World Probability: 0.22548177239302347
Real World Truth Ratio: 0.6339589736404829
Real World Token Entropy: 0.8888634819662119
Real World Cosine Similarity: 0.6496291289106011
Real World Entailment Score: 0.66
Retain ROUGE: 0.5209960664404482
Retain Probability: 0.9811293095314458
Retain Truth Ratio: 0.4382991838020762
Retain Token Entropy: 0.9559659785613932
Retain Cosine Similarity: 0.8149292403211196
Retain Entailment Score: 0.34
Forget ROUGE: 0.5189052838418006
Forget Probability: 0.37152197663017716
Forget Truth Ratio: 0.9156857627663115
Forget Token Entropy: 0.9645657450022653
Forget Cosine Similarity: 0.8593296483159065
Forget Entailment Score: 0.35
Model Utility Retain: 0.5750144873115195
Model Utility: 0.6107417549073278
Forget Efficacy: 0.3969114656891608
split: forget01
forget_loss: NPO2+GD2
forget_coeff: 1.0
regularization_coeff: 1.0
learning_rate: 1e-05
epochs: 1
fix_ref_model: 
mask: True
unlearn_step: last
task_id: 1
unlearn_times: 1
