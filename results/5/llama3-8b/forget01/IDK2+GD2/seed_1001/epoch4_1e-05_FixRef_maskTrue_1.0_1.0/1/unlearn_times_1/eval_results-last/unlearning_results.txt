Real Authors ROUGE: 0.29333333333333333
Real Authors Probability: 0.6590741062507262
Real Authors Truth Ratio: 0.9041865875047828
Real Authors Token Entropy: 0.9316853397821575
Real Authors Cosine Similarity: 0.27277937621809545
Real Authors Entailment Score: 0.28
Real World ROUGE: 0.68
Real World Probability: 0.2900541160580664
Real World Truth Ratio: 0.6101572625614398
Real World Token Entropy: 0.8843342774751298
Real World Cosine Similarity: 0.5130564318224787
Real World Entailment Score: 0.54
Retain ROUGE: 0.0818735988481913
Retain Probability: 0.8561775781638661
Retain Truth Ratio: 0.39964654149886886
Retain Token Entropy: 0.9519835645261899
Retain Cosine Similarity: 0.1797195188080271
Retain Entailment Score: 0.07666666666666666
Forget ROUGE: 0.008476272105512817
Forget Probability: 0.3864631548374019
Forget Truth Ratio: 0.9045052164328119
Forget Token Entropy: 0.9238377377264536
Forget Cosine Similarity: 0.03868213023524732
Forget Entailment Score: 0.0
Model Utility Retain: 0.16881300679298958
Model Utility: 0.29328268854564493
Forget Efficacy: 0.7323746452778052
split: forget01
forget_loss: IDK2+GD2
forget_coeff: 1.0
regularization_coeff: 1.0
learning_rate: 1e-05
epochs: 4
fix_ref_model: 
mask: True
unlearn_step: last
task_id: 1
unlearn_times: 1
