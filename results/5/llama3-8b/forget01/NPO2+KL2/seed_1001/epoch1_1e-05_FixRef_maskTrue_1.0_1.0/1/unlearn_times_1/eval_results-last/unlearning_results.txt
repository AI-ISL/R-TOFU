Real Authors ROUGE: 0.7985
Real Authors Probability: 0.5910505862571764
Real Authors Truth Ratio: 0.9062449400901056
Real Authors Token Entropy: 0.9645575359790673
Real Authors Cosine Similarity: 0.8045765456184745
Real Authors Entailment Score: 0.75
Real World ROUGE: 0.7675
Real World Probability: 0.22469511324864544
Real World Truth Ratio: 0.6331614791713749
Real World Token Entropy: 0.9096013306234851
Real World Cosine Similarity: 0.65846205342561
Real World Entailment Score: 0.61
Retain ROUGE: 0.5251526182022851
Retain Probability: 0.9810871794999529
Retain Truth Ratio: 0.4380061000330007
Retain Token Entropy: 0.9484720453613363
Retain Cosine Similarity: 0.8139788526544969
Retain Entailment Score: 0.3433333333333333
Forget ROUGE: 0.5187894296241045
Forget Probability: 0.37176173241815824
Forget Truth Ratio: 0.9160777068123636
Forget Token Entropy: 0.9658593735700032
Forget Cosine Similarity: 0.8549830049276352
Forget Entailment Score: 0.35
Model Utility Retain: 0.5768098878926048
Model Utility: 0.6070229742890271
Forget Efficacy: 0.39767762524354766
split: forget01
forget_loss: NPO2+KL2
forget_coeff: 1.0
regularization_coeff: 1.0
learning_rate: 1e-05
epochs: 1
fix_ref_model: 
mask: True
unlearn_step: last
task_id: 1
unlearn_times: 1
