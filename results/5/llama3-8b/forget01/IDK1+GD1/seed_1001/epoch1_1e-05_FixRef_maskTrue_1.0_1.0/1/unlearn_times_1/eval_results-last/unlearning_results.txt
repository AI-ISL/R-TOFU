Real Authors ROUGE: 0.6893333333333334
Real Authors Probability: 0.6327803569120115
Real Authors Truth Ratio: 0.9092079588346776
Real Authors Token Entropy: 0.9531321589194098
Real Authors Cosine Similarity: 0.7582378859072924
Real Authors Entailment Score: 0.67
Real World ROUGE: 0.8003333333333333
Real World Probability: 0.2718800811923571
Real World Truth Ratio: 0.6399120712552052
Real World Token Entropy: 0.8585823904874575
Real World Cosine Similarity: 0.6565931348875165
Real World Entailment Score: 0.6
Retain ROUGE: 0.4921600090690426
Retain Probability: 0.9841977679919867
Retain Truth Ratio: 0.4269649303800811
Retain Token Entropy: 0.9473522645118297
Retain Cosine Similarity: 0.7974651239688197
Retain Entailment Score: 0.37333333333333335
Forget ROUGE: 0.4875446599345736
Forget Probability: 0.43490688958966733
Forget Truth Ratio: 0.910292370382932
Forget Token Entropy: 0.9179716938215196
Forget Cosine Similarity: 0.8242931640706956
Forget Entailment Score: 0.35
Model Utility Retain: 0.5781379156216153
Model Utility: 0.6161378232608133
Forget Efficacy: 0.39859258320442625
split: forget01
forget_loss: IDK1+GD1
forget_coeff: 1.0
regularization_coeff: 1.0
learning_rate: 1e-05
epochs: 1
fix_ref_model: 
mask: True
unlearn_step: last
task_id: 1
unlearn_times: 1
