Real Authors ROUGE: 0.41700000000000004
Real Authors Probability: 0.660641881257176
Real Authors Truth Ratio: 0.9051233685432591
Real Authors Token Entropy: 0.9620087608620566
Real Authors Cosine Similarity: 0.41096060290001335
Real Authors Entailment Score: 0.4
Real World ROUGE: 0.7186666666666668
Real World Probability: 0.32070126310396363
Real World Truth Ratio: 0.6317609059266998
Real World Token Entropy: 0.8978692223073775
Real World Cosine Similarity: 0.6192713686451315
Real World Entailment Score: 0.56
Retain ROUGE: 0.2119007713738769
Retain Probability: 0.9555613253538547
Retain Truth Ratio: 0.40217147374363066
Retain Token Entropy: 0.9824487911129042
Retain Cosine Similarity: 0.3996978392265737
Retain Entailment Score: 0.16
Forget ROUGE: 0.03901586333936439
Forget Probability: 0.40228941406334584
Forget Truth Ratio: 0.9037662938533243
Forget Token Entropy: 0.9469931264863891
Forget Cosine Similarity: 0.16350749467965214
Forget Entailment Score: 0.025
Model Utility Retain: 0.3329273181059001
Model Utility: 0.4543375380636503
Forget Efficacy: 0.6932841868128626
split: forget01
forget_loss: IDK1+GD1
forget_coeff: 1.0
regularization_coeff: 1.0
learning_rate: 1e-05
epochs: 5
fix_ref_model: 
mask: True
unlearn_step: last
task_id: 1
unlearn_times: 1
