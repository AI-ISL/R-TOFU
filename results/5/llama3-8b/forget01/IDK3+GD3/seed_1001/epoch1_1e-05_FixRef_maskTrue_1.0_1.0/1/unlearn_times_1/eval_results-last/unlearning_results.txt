Real Authors ROUGE: 0.6611666666666666
Real Authors Probability: 0.6356083433120303
Real Authors Truth Ratio: 0.909600296946817
Real Authors Token Entropy: 0.9353823260191672
Real Authors Cosine Similarity: 0.7295577663555741
Real Authors Entailment Score: 0.61
Real World ROUGE: 0.787
Real World Probability: 0.27461959044334694
Real World Truth Ratio: 0.6423497755204032
Real World Token Entropy: 0.8206188003878399
Real World Cosine Similarity: 0.6350175005570055
Real World Entailment Score: 0.61
Retain ROUGE: 0.5008691650869918
Retain Probability: 0.9850967537248975
Retain Truth Ratio: 0.4264406494086617
Retain Token Entropy: 0.9277238812539456
Retain Cosine Similarity: 0.7913393537948529
Retain Entailment Score: 0.3566666666666667
Forget ROUGE: 0.4977505771875249
Forget Probability: 0.43555002337828264
Forget Truth Ratio: 0.9105022965333489
Forget Token Entropy: 0.9678347865379713
Forget Cosine Similarity: 0.8387612087652088
Forget Entailment Score: 0.3
Model Utility Retain: 0.5713210596061975
Model Utility: 0.6067187504098144
Forget Efficacy: 0.4034871788271269
split: forget01
forget_loss: IDK3+GD3
forget_coeff: 1.0
regularization_coeff: 1.0
learning_rate: 1e-05
epochs: 1
fix_ref_model: 
mask: True
unlearn_step: last
task_id: 1
unlearn_times: 1
