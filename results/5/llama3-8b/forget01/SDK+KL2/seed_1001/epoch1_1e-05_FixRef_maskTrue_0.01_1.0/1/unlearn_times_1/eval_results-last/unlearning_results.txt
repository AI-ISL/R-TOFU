Real Authors ROUGE: 0.7818333333333334
Real Authors Probability: 0.6099540094960302
Real Authors Truth Ratio: 0.9062152400193476
Real Authors Token Entropy: 0.981277862398386
Real Authors Cosine Similarity: 0.8157548693940043
Real Authors Entailment Score: 0.76
Real World ROUGE: 0.8303333333333334
Real World Probability: 0.25025637445907783
Real World Truth Ratio: 0.6240166709617607
Real World Token Entropy: 0.9082207615439921
Real World Cosine Similarity: 0.6576193365827203
Real World Entailment Score: 0.67
Retain ROUGE: 0.47990128649525937
Retain Probability: 0.9865955894622201
Retain Truth Ratio: 0.42894129715688023
Retain Token Entropy: 0.9147765488603553
Retain Cosine Similarity: 0.7746429966886839
Retain Entailment Score: 0.3466666666666667
Forget ROUGE: 0.5058538046399617
Forget Probability: 0.43170570118789203
Forget Truth Ratio: 0.9112393822996063
Forget Token Entropy: 0.9149323681152491
Forget Cosine Similarity: 0.8198771061375737
Forget Entailment Score: 0.375
Model Utility Retain: 0.5608857621803307
Model Utility: 0.6164999412494292
Forget Efficacy: 0.39126480114699325
split: forget01
forget_loss: SDK+KL2
forget_coeff: 0.01
regularization_coeff: 1.0
learning_rate: 1e-05
epochs: 1
fix_ref_model: 
mask: True
unlearn_step: last
task_id: 1
unlearn_times: 1
