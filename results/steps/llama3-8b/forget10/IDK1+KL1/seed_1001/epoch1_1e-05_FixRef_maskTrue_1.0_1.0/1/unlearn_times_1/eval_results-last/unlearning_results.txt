Real Authors ROUGE: 0.06
Real Authors Probability: 0.6035310810966462
Real Authors Truth Ratio: 0.8946690700824973
Real Authors Token Entropy: 0.1477016454333106
Real Authors Cosine Similarity: 0.095759031875059
Real Authors Entailment Score: 0.06
Real World ROUGE: 0.16166666666666665
Real World Probability: 0.29183421788181213
Real World Truth Ratio: 0.6199431394468613
Real World Token Entropy: 0.3075000434444089
Real World Cosine Similarity: 0.1375636703055352
Real World Entailment Score: 0.12
Retain ROUGE: 0.030312166289823493
Retain Probability: 0.8688849585385735
Retain Truth Ratio: 0.37333746935350715
Retain Token Entropy: 0.28761826490180264
Retain Cosine Similarity: 0.13678882189560682
Retain Entailment Score: 0.03
Forget ROUGE: 0.02308802633859708
Forget Probability: 0.40527352998700344
Forget Truth Ratio: 0.9186606655044588
Forget Token Entropy: 0.2069322900134185
Forget Cosine Similarity: 0.12715024221378068
Forget Entailment Score: 0.006666666666666667
Model Utility Retain: 0.07412880229729696
Model Utility: 0.10952808442240937
Forget Efficacy: 0.7038321738578986
split: forget10
forget_loss: IDK1+KL1
forget_coeff: 1.0
regularization_coeff: 1.0
learning_rate: 1e-05
epochs: 1
fix_ref_model: 
mask: True
unlearn_step: last
task_id: 1
unlearn_times: 1
