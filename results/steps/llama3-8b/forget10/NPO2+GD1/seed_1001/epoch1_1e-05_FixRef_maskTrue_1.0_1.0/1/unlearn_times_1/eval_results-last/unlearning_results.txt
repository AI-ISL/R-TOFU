Real Authors ROUGE: 0.6868333333333334
Real Authors Probability: 0.28062933678346835
Real Authors Truth Ratio: 0.874652430338024
Real Authors Token Entropy: 0.9832985469727601
Real Authors Cosine Similarity: 0.8702913892269134
Real Authors Entailment Score: 0.64
Real World ROUGE: 0.7816666666666667
Real World Probability: 0.07953730880997764
Real World Truth Ratio: 0.6052583163128943
Real World Token Entropy: 0.966913428963079
Real World Cosine Similarity: 0.8564997160434723
Real World Entailment Score: 0.7
Retain ROUGE: 0.5241150626238578
Retain Probability: 0.5024317251207909
Retain Truth Ratio: 0.4922777881122089
Retain Token Entropy: 0.9473887420206449
Retain Cosine Similarity: 0.826702426870664
Retain Entailment Score: 0.4266666666666667
Forget ROUGE: 0.5249753388367401
Forget Probability: 0.1397852670951949
Forget Truth Ratio: 0.9524723651746826
Forget Token Entropy: 0.9486441909456681
Forget Cosine Similarity: 0.8482127485672633
Forget Entailment Score: 0.3933333333333333
Model Utility Retain: 0.569336689688245
Model Utility: 0.45495506565437005
Forget Efficacy: 0.42824418939855724
split: forget10
forget_loss: NPO2+GD1
forget_coeff: 1.0
regularization_coeff: 1.0
learning_rate: 1e-05
epochs: 1
fix_ref_model: 
mask: True
unlearn_step: last
task_id: 1
unlearn_times: 1
