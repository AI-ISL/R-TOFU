Real Authors ROUGE: 0.6525
Real Authors Probability: 0.3830451945275367
Real Authors Truth Ratio: 0.9020810025119329
Real Authors Token Entropy: 0.9829503990265239
Real Authors Cosine Similarity: 0.8346614763140678
Real Authors Entailment Score: 0.6
Real World ROUGE: 0.7516666666666666
Real World Probability: 0.12165966799709117
Real World Truth Ratio: 0.6178539763733097
Real World Token Entropy: 0.9497315197376444
Real World Cosine Similarity: 0.8166755175590515
Real World Entailment Score: 0.65
Retain ROUGE: 0.6217421668641596
Retain Probability: 0.8214806741756133
Retain Truth Ratio: 0.4860138253176161
Retain Token Entropy: 0.9576802024480211
Retain Cosine Similarity: 0.8615529733896256
Retain Entailment Score: 0.4766666666666667
Forget ROUGE: 0.5979112807178398
Forget Probability: 0.19201051394648402
Forget Truth Ratio: 0.950922405995466
Forget Token Entropy: 0.9503662998247592
Forget Cosine Similarity: 0.8713910878201325
Forget Entailment Score: 0.53
Model Utility Retain: 0.6531650754604219
Model Utility: 0.5404705043156787
Forget Efficacy: 0.3715529423040156
split: forget10
forget_loss: NPO2+KL1
forget_coeff: 1.0
regularization_coeff: 1.0
learning_rate: 1e-05
epochs: 1
fix_ref_model: 
mask: True
unlearn_step: last
task_id: 1
unlearn_times: 1
