Real Authors ROUGE: 0.05533333333333333
Real Authors Probability: 0.6498275743430539
Real Authors Truth Ratio: 0.9034606246820063
Real Authors Token Entropy: 0.977404494911531
Real Authors Cosine Similarity: 0.11762877520173788
Real Authors Entailment Score: 0.05
Real World ROUGE: 0.26666666666666666
Real World Probability: 0.3243279891556574
Real World Truth Ratio: 0.631662075357611
Real World Token Entropy: 0.9743467132820121
Real World Cosine Similarity: 0.26852391165681183
Real World Entailment Score: 0.23
Retain ROUGE: 0.02416635244715368
Retain Probability: 0.9499296263732155
Retain Truth Ratio: 0.39307924281665446
Retain Token Entropy: 0.9914048584076111
Retain Cosine Similarity: 0.09166322357021273
Retain Entailment Score: 0.013333333333333334
Forget ROUGE: 0.004527889784946237
Forget Probability: 0.37033268251391127
Forget Truth Ratio: 0.9023933752381746
Forget Token Entropy: 1.0
Forget Cosine Similarity: 0.050282721710391345
Forget Entailment Score: 0.0
Model Utility Retain: 0.04549081936107419
Model Utility: 0.09015694564975653
Forget Efficacy: 0.7344926661505153
split: forget01
forget_loss: IDK1
forget_coeff: 1.0
regularization_coeff: 1.0
learning_rate: 1e-05
epochs: 7
fix_ref_model: 
mask: True
unlearn_step: last
task_id: 1
unlearn_times: 1
