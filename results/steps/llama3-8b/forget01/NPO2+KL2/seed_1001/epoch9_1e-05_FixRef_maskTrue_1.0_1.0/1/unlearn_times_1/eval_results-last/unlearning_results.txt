Real Authors ROUGE: 0.3516666666666666
Real Authors Probability: 0.2952413970990556
Real Authors Truth Ratio: 0.9014172733058351
Real Authors Token Entropy: 0.756169361816449
Real Authors Cosine Similarity: 0.32676275048404935
Real Authors Entailment Score: 0.32
Real World ROUGE: 0.5566666666666666
Real World Probability: 0.09407208368660255
Real World Truth Ratio: 0.6018066691049778
Real World Token Entropy: 0.7770321761886294
Real World Cosine Similarity: 0.4043754932843149
Real World Entailment Score: 0.49
Retain ROUGE: 0.24402167288836665
Retain Probability: 0.18449594225747365
Retain Truth Ratio: 0.4657949618819329
Retain Token Entropy: 0.7080563919252673
Retain Cosine Similarity: 0.3871104219711075
Retain Entailment Score: 0.4266666666666667
Forget ROUGE: 0.17455169493368908
Forget Probability: 0.02059435448044703
Forget Truth Ratio: 0.927110815817681
Forget Token Entropy: 0.6881311662186391
Forget Cosine Similarity: 0.32993013262748716
Forget Entailment Score: 0.225
Model Utility Retain: 0.33325286073061683
Model Utility: 0.34128993389492607
Forget Efficacy: 0.6645626004281391
split: forget01
forget_loss: NPO2+KL2
forget_coeff: 1.0
regularization_coeff: 1.0
learning_rate: 1e-05
epochs: 9
fix_ref_model: 
mask: True
unlearn_step: last
task_id: 1
unlearn_times: 1
