Real Authors ROUGE: 0.6835
Real Authors Probability: 0.46064520226528066
Real Authors Truth Ratio: 0.9061426392322897
Real Authors Token Entropy: 0.9938100098810194
Real Authors Cosine Similarity: 0.6687399404495955
Real Authors Entailment Score: 0.63
Real World ROUGE: 0.7558333333333332
Real World Probability: 0.13959386696068804
Real World Truth Ratio: 0.6084638702774885
Real World Token Entropy: 0.9190676125984873
Real World Cosine Similarity: 0.6572908727824688
Real World Entailment Score: 0.65
Retain ROUGE: 0.46333951431702275
Retain Probability: 0.5918240463500946
Retain Truth Ratio: 0.47093651261313607
Retain Token Entropy: 0.9510615147128355
Retain Cosine Similarity: 0.7316656558588147
Retain Entailment Score: 0.46
Forget ROUGE: 0.3624108868043153
Forget Probability: 0.05536155066300276
Forget Truth Ratio: 0.9324964043976552
Forget Token Entropy: 0.9408158298843781
Forget Cosine Similarity: 0.6356963533908129
Forget Entailment Score: 0.25
Model Utility Retain: 0.5679947087157003
Model Utility: 0.5346331643741471
Forget Efficacy: 0.5528069609488429
split: forget01
forget_loss: NPO2+KL2
forget_coeff: 1.0
regularization_coeff: 1.0
learning_rate: 1e-05
epochs: 6
fix_ref_model: 
mask: True
unlearn_step: last
task_id: 1
unlearn_times: 1
