Real Authors ROUGE: 0.6793333333333333
Real Authors Probability: 0.4593607072886877
Real Authors Truth Ratio: 0.9071662215507996
Real Authors Token Entropy: 0.9860011444074194
Real Authors Cosine Similarity: 0.8029310424625874
Real Authors Entailment Score: 0.62
Real World ROUGE: 0.7966666666666667
Real World Probability: 0.14334518793226209
Real World Truth Ratio: 0.6096703780091193
Real World Token Entropy: 0.9414501369762143
Real World Cosine Similarity: 0.7056560572236776
Real World Entailment Score: 0.65
Retain ROUGE: 0.5482673584538048
Retain Probability: 0.9983872961467449
Retain Truth Ratio: 0.48562756479885155
Retain Token Entropy: 0.949989566857571
Retain Cosine Similarity: 0.8237717157105605
Retain Entailment Score: 0.32666666666666666
Forget ROUGE: 0.45452742533228474
Forget Probability: 0.13460991609519407
Forget Truth Ratio: 0.9365843924366182
Forget Token Entropy: 0.9594801760211146
Forget Cosine Similarity: 0.7981980964541435
Forget Entailment Score: 0.175
Model Utility Retain: 0.5875135552511439
Model Utility: 0.5500251981957713
Forget Efficacy: 0.500216033936352
split: forget01
forget_loss: GA1+GD1
forget_coeff: 1.0
regularization_coeff: 1.0
learning_rate: 1e-05
epochs: 3
fix_ref_model: 
mask: True
unlearn_step: last
task_id: 1
unlearn_times: 1
