Real Authors ROUGE: 0.5458333333333333
Real Authors Probability: 0.6527501920445424
Real Authors Truth Ratio: 0.9095376873915514
Real Authors Token Entropy: 0.875177050634695
Real Authors Cosine Similarity: 0.647929557710886
Real Authors Entailment Score: 0.54
Real World ROUGE: 0.772
Real World Probability: 0.3244253085837541
Real World Truth Ratio: 0.643531655627576
Real World Token Entropy: 0.8366782662498496
Real World Cosine Similarity: 0.6632167121767998
Real World Entailment Score: 0.6
Retain ROUGE: 0.5566770050897324
Retain Probability: 0.9966985678123107
Retain Truth Ratio: 0.4193902449232359
Retain Token Entropy: 0.9523592583502866
Retain Cosine Similarity: 0.831824217022707
Retain Entailment Score: 0.47
Forget ROUGE: 0.44391976723961585
Forget Probability: 0.44688490779312107
Forget Truth Ratio: 0.9071765453221706
Forget Token Entropy: 0.9706058453707513
Forget Cosine Similarity: 0.7567667469382287
Forget Entailment Score: 0.2
Model Utility Retain: 0.6273551420547095
Model Utility: 0.6235575012949167
Forget Efficacy: 0.44905040654137274
split: forget01
forget_loss: IDK3+KL1
forget_coeff: 1.0
regularization_coeff: 1.0
learning_rate: 1e-05
epochs: 4
fix_ref_model: 
mask: True
unlearn_step: last
task_id: 1
unlearn_times: 1
