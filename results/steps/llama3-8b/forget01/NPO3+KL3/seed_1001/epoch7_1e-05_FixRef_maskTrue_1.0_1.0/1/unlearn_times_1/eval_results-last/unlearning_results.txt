Real Authors ROUGE: 0.6858333333333333
Real Authors Probability: 0.2598655109864795
Real Authors Truth Ratio: 0.8560787051656455
Real Authors Token Entropy: 0.4265766064391924
Real Authors Cosine Similarity: 0.5883233588188886
Real Authors Entailment Score: 0.7
Real World ROUGE: 0.7383333333333334
Real World Probability: 0.052972686435565935
Real World Truth Ratio: 0.5174258713960603
Real World Token Entropy: 0.3502039043658812
Real World Cosine Similarity: 0.5027797838300466
Real World Entailment Score: 0.77
Retain ROUGE: 0.6059103917902001
Retain Probability: 0.06705741886038008
Retain Truth Ratio: 0.42600082993696237
Retain Token Entropy: 0.4919751050326308
Retain Cosine Similarity: 0.7435745319724083
Retain Entailment Score: 0.9966666666666667
Forget ROUGE: 0.5995246634435933
Forget Probability: 0.017619240530571394
Forget Truth Ratio: 0.9159972090889231
Forget Token Entropy: 0.5182008182269626
Forget Cosine Similarity: 0.7939961329102516
Forget Entailment Score: 1.0
Model Utility Retain: 0.25760760163118207
Model Utility: 0.2832595349801388
Forget Efficacy: 0.3345725508053321
split: forget01
forget_loss: NPO3+KL3
forget_coeff: 1.0
regularization_coeff: 1.0
learning_rate: 1e-05
epochs: 7
fix_ref_model: 
mask: True
unlearn_step: last
task_id: 1
unlearn_times: 1
