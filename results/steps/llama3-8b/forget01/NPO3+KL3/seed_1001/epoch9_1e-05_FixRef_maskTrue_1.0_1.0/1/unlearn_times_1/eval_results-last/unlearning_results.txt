Real Authors ROUGE: 0.62
Real Authors Probability: 0.16595354464792467
Real Authors Truth Ratio: 0.83717154698147
Real Authors Token Entropy: 0.3842470108806858
Real Authors Cosine Similarity: 0.46986332066357134
Real Authors Entailment Score: 0.64
Real World ROUGE: 0.7658333333333333
Real World Probability: 0.03183882158914783
Real World Truth Ratio: 0.5022903652153885
Real World Token Entropy: 0.36321021236833856
Real World Cosine Similarity: 0.4847688940912485
Real World Entailment Score: 0.8
Retain ROUGE: 0.5430125042793598
Retain Probability: 0.036151596893172336
Retain Truth Ratio: 0.4246162751018927
Retain Token Entropy: 0.4778799812723961
Retain Cosine Similarity: 0.6913099524875482
Retain Entailment Score: 0.99
Forget ROUGE: 0.5398191705133852
Forget Probability: 0.008614172636504307
Forget Truth Ratio: 0.9094960419056651
Forget Token Entropy: 0.5158273599124817
Forget Cosine Similarity: 0.7331197142601014
Forget Entailment Score: 1.0
Model Utility Retain: 0.16480280686102156
Model Utility: 0.19500671762472402
Forget Efficacy: 0.3617901801368688
split: forget01
forget_loss: NPO3+KL3
forget_coeff: 1.0
regularization_coeff: 1.0
learning_rate: 1e-05
epochs: 9
fix_ref_model: 
mask: True
unlearn_step: last
task_id: 1
unlearn_times: 1
