Real Authors ROUGE: 0.6708333333333333
Real Authors Probability: 0.33392478220523203
Real Authors Truth Ratio: 0.8740470710035747
Real Authors Token Entropy: 0.6275899389612883
Real Authors Cosine Similarity: 0.6961409270763397
Real Authors Entailment Score: 0.68
Real World ROUGE: 0.7553333333333333
Real World Probability: 0.07548138066571247
Real World Truth Ratio: 0.5430519985303526
Real World Token Entropy: 0.5278420442439241
Real World Cosine Similarity: 0.5897179326415062
Real World Entailment Score: 0.78
Retain ROUGE: 0.6454500767252017
Retain Probability: 0.09375169807510465
Retain Truth Ratio: 0.42830846517364646
Retain Token Entropy: 0.5139313367130505
Retain Cosine Similarity: 0.7748217140634854
Retain Entailment Score: 0.9966666666666667
Forget ROUGE: 0.5862717114415646
Forget Probability: 0.02330227367414352
Forget Truth Ratio: 0.9241439426412044
Forget Token Entropy: 0.5339911728067159
Forget Cosine Similarity: 0.8001709282398224
Forget Entailment Score: 0.975
Model Utility Retain: 0.3193137724554152
Model Utility: 0.3585215238603586
Forget Efficacy: 0.338222228800653
split: forget01
forget_loss: NPO3+KL3
forget_coeff: 1.0
regularization_coeff: 1.0
learning_rate: 1e-05
epochs: 5
fix_ref_model: 
mask: True
unlearn_step: last
task_id: 1
unlearn_times: 1
