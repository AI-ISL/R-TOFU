Real Authors ROUGE: 0.6228333333333333
Real Authors Probability: 0.39250395030424945
Real Authors Truth Ratio: 0.896632810596142
Real Authors Token Entropy: 0.9780957327521181
Real Authors Cosine Similarity: 0.710085956081748
Real Authors Entailment Score: 0.57
Real World ROUGE: 0.7858333333333333
Real World Probability: 0.10961714851579243
Real World Truth Ratio: 0.606763409763613
Real World Token Entropy: 0.9624691439718446
Real World Cosine Similarity: 0.7074478896707297
Real World Entailment Score: 0.57
Retain ROUGE: 0.39565400477928875
Retain Probability: 0.2695329306923715
Retain Truth Ratio: 0.5003474240343379
Retain Token Entropy: 0.9505588542933905
Retain Cosine Similarity: 0.6531061751643816
Retain Entailment Score: 0.3566666666666667
Forget ROUGE: 0.2694218340525404
Forget Probability: 0.01758540974049941
Forget Truth Ratio: 0.9284145160730256
Forget Token Entropy: 0.9299838937956035
Forget Cosine Similarity: 0.5837855696678161
Forget Entailment Score: 0.2
Model Utility Retain: 0.44042872834099966
Model Utility: 0.4577015053450572
Forget Efficacy: 0.6001585340932237
split: forget01
forget_loss: GA2+KL2
forget_coeff: 1.0
regularization_coeff: 1.0
learning_rate: 1e-05
epochs: 7
fix_ref_model: 
mask: True
unlearn_step: last
task_id: 1
unlearn_times: 1
