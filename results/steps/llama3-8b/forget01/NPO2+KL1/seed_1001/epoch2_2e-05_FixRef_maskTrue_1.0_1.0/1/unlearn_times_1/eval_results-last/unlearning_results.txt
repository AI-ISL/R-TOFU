Real Authors ROUGE: 0.6468333333333334
Real Authors Probability: 0.4746294343103705
Real Authors Truth Ratio: 0.9069948474748819
Real Authors Token Entropy: 0.9846580419839196
Real Authors Cosine Similarity: 0.8219636482000351
Real Authors Entailment Score: 0.59
Real World ROUGE: 0.8125
Real World Probability: 0.14865447473494897
Real World Truth Ratio: 0.6183685674987508
Real World Token Entropy: 0.9515599150247069
Real World Cosine Similarity: 0.7492908361926675
Real World Entailment Score: 0.67
Retain ROUGE: 0.5890153667813028
Retain Probability: 0.8566900693153378
Retain Truth Ratio: 0.46795700375113775
Retain Token Entropy: 0.9544687085096526
Retain Cosine Similarity: 0.8208462601403396
Retain Entailment Score: 0.49333333333333335
Forget ROUGE: 0.3364236579932761
Forget Probability: 0.1272708494927593
Forget Truth Ratio: 0.9279145839592278
Forget Token Entropy: 0.9595668532673507
Forget Cosine Similarity: 0.64135083258152
Forget Entailment Score: 0.225
Model Utility Retain: 0.6455107293979873
Model Utility: 0.572692526709115
Forget Efficacy: 0.5484080151946433
split: forget01
forget_loss: NPO2+KL1
forget_coeff: 1.0
regularization_coeff: 1.0
learning_rate: 2e-05
epochs: 2
fix_ref_model: 
mask: True
unlearn_step: last
task_id: 1
unlearn_times: 1
