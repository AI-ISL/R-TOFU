Real Authors ROUGE: 0.6591666666666666
Real Authors Probability: 0.5161392485079345
Real Authors Truth Ratio: 0.9075999945856631
Real Authors Token Entropy: 0.9849178335805694
Real Authors Cosine Similarity: 0.796040668822825
Real Authors Entailment Score: 0.63
Real World ROUGE: 0.7683333333333334
Real World Probability: 0.18210272742127379
Real World Truth Ratio: 0.6294148448354702
Real World Token Entropy: 0.9466308984154432
Real World Cosine Similarity: 0.7408164907991887
Real World Entailment Score: 0.64
Retain ROUGE: 0.6904942399502794
Retain Probability: 0.9993462569728057
Retain Truth Ratio: 0.4680591729613347
Retain Token Entropy: 0.9616789431379512
Retain Cosine Similarity: 0.8927688687046369
Retain Entailment Score: 0.5766666666666667
Forget ROUGE: 0.5373666069272526
Forget Probability: 0.2708058921162051
Forget Truth Ratio: 0.927787832258862
Forget Token Entropy: 0.9590644005070077
Forget Cosine Similarity: 0.8452742669731379
Forget Entailment Score: 0.35
Model Utility Retain: 0.7075941443122107
Model Utility: 0.6154888558642218
Forget Efficacy: 0.41375308034490843
split: forget01
forget_loss: NPO1+GD1
forget_coeff: 1.0
regularization_coeff: 1.0
learning_rate: 1e-05
epochs: 1
fix_ref_model: 
mask: True
unlearn_step: last
task_id: 1
unlearn_times: 1
