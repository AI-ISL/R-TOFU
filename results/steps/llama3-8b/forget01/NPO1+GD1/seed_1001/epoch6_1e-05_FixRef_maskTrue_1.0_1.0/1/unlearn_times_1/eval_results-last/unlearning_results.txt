Real Authors ROUGE: 0.6508333333333333
Real Authors Probability: 0.5183758289275527
Real Authors Truth Ratio: 0.911294043663383
Real Authors Token Entropy: 0.9858935641475047
Real Authors Cosine Similarity: 0.7872545632719994
Real Authors Entailment Score: 0.61
Real World ROUGE: 0.7916666666666665
Real World Probability: 0.18813277332716205
Real World Truth Ratio: 0.6432846692078134
Real World Token Entropy: 0.9413765771549838
Real World Cosine Similarity: 0.7361799724400043
Real World Entailment Score: 0.64
Retain ROUGE: 0.5554737586634312
Retain Probability: 0.9986082309324725
Retain Truth Ratio: 0.4647408113387204
Retain Token Entropy: 0.9598371462461913
Retain Cosine Similarity: 0.8338349776466688
Retain Entailment Score: 0.38
Forget ROUGE: 0.4331457722997681
Forget Probability: 0.15709406438220525
Forget Truth Ratio: 0.9279319561324259
Forget Token Entropy: 0.9552818549342319
Forget Cosine Similarity: 0.7990534618496895
Forget Entailment Score: 0.175
Model Utility Retain: 0.6106188952365111
Model Utility: 0.5915383832791862
Forget Efficacy: 0.5015549490671823
split: forget01
forget_loss: NPO1+GD1
forget_coeff: 1.0
regularization_coeff: 1.0
learning_rate: 1e-05
epochs: 6
fix_ref_model: 
mask: True
unlearn_step: last
task_id: 1
unlearn_times: 1
