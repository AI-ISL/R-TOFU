Real Authors ROUGE: 0.6591666666666666
Real Authors Probability: 0.5079619604576856
Real Authors Truth Ratio: 0.9090011408867056
Real Authors Token Entropy: 0.9848635482051721
Real Authors Cosine Similarity: 0.8051086041331291
Real Authors Entailment Score: 0.62
Real World ROUGE: 0.7866666666666667
Real World Probability: 0.1769943252941213
Real World Truth Ratio: 0.6321282407046294
Real World Token Entropy: 0.9336174312394191
Real World Cosine Similarity: 0.7427505907416344
Real World Entailment Score: 0.65
Retain ROUGE: 0.5652412638818373
Retain Probability: 0.9988893386676333
Retain Truth Ratio: 0.4671353199754263
Retain Token Entropy: 0.9567252009254116
Retain Cosine Similarity: 0.840151881352067
Retain Entailment Score: 0.4
Forget ROUGE: 0.45735828897997466
Forget Probability: 0.174847664994495
Forget Truth Ratio: 0.9280086914204407
Forget Token Entropy: 0.9549028476007445
Forget Cosine Similarity: 0.7963781744241715
Forget Entailment Score: 0.225
Model Utility Retain: 0.6219892830535976
Model Utility: 0.5889745954108362
Forget Efficacy: 0.48368143603618363
split: forget01
forget_loss: NPO1+GD1
forget_coeff: 1.0
regularization_coeff: 1.0
learning_rate: 1e-05
epochs: 5
fix_ref_model: 
mask: True
unlearn_step: last
task_id: 1
unlearn_times: 1
