Real Authors ROUGE: 0.39433333333333337
Real Authors Probability: 0.3671445421524417
Real Authors Truth Ratio: 0.8713920336040224
Real Authors Token Entropy: 0.901708472649847
Real Authors Cosine Similarity: 0.4711950111016631
Real Authors Entailment Score: 0.09
Real World ROUGE: 0.6033333333333333
Real World Probability: 0.09927047794242777
Real World Truth Ratio: 0.5619000865487844
Real World Token Entropy: 0.8955589428664532
Real World Cosine Similarity: 0.6042857520282269
Real World Entailment Score: 0.2
Retain ROUGE: 0.3453091029148058
Retain Probability: 0.38772874965145016
Retain Truth Ratio: 0.4349281330077455
Retain Token Entropy: 0.9066878464570622
Retain Cosine Similarity: 0.6296104832490286
Retain Entailment Score: 0.26
Forget ROUGE: 0.20866256121523968
Forget Probability: 0.01595687440683035
Forget Truth Ratio: 0.9061128770503513
Forget Token Entropy: 0.9112575960390938
Forget Cosine Similarity: 0.4166305066086352
Forget Entailment Score: 0.05
Model Utility Retain: 0.4192385195663554
Model Utility: 0.3194697074183314
Forget Efficacy: 0.6805274361437887
split: forget01
forget_loss: NPO2+GD1
forget_coeff: 1.0
regularization_coeff: 1.0
learning_rate: 5e-05
epochs: 4
fix_ref_model: 
mask: True
unlearn_step: last
task_id: 1
unlearn_times: 1
