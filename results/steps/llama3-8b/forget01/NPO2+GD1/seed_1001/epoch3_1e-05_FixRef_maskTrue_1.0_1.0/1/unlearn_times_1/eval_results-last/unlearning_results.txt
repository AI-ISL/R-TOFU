Real Authors ROUGE: 0.6681666666666666
Real Authors Probability: 0.49599978160839187
Real Authors Truth Ratio: 0.9054149972076219
Real Authors Token Entropy: 0.9887626057030323
Real Authors Cosine Similarity: 0.7554328188300132
Real Authors Entailment Score: 0.67
Real World ROUGE: 0.7566666666666666
Real World Probability: 0.15150471296025314
Real World Truth Ratio: 0.6110767239111986
Real World Token Entropy: 0.9355367054969568
Real World Cosine Similarity: 0.7040218597650528
Real World Entailment Score: 0.59
Retain ROUGE: 0.6632995460202235
Retain Probability: 0.9564550214440747
Retain Truth Ratio: 0.47445986112226307
Retain Token Entropy: 0.9572695618885703
Retain Cosine Similarity: 0.878512004117171
Retain Entailment Score: 0.5833333333333334
Forget ROUGE: 0.488171313904701
Forget Probability: 0.17090578561372083
Forget Truth Ratio: 0.9309245841138908
Forget Token Entropy: 0.9668720703975392
Forget Cosine Similarity: 0.8082057021558284
Forget Entailment Score: 0.475
Model Utility Retain: 0.7010972633764067
Model Utility: 0.5854493168504198
Forget Efficacy: 0.42535852284237174
split: forget01
forget_loss: NPO2+GD1
forget_coeff: 1.0
regularization_coeff: 1.0
learning_rate: 1e-05
epochs: 3
fix_ref_model: 
mask: True
unlearn_step: last
task_id: 1
unlearn_times: 1
