Real Authors ROUGE: 0.6418333333333334
Real Authors Probability: 0.46563759828341217
Real Authors Truth Ratio: 0.9051614842307565
Real Authors Token Entropy: 0.9843942194495239
Real Authors Cosine Similarity: 0.8198908561468125
Real Authors Entailment Score: 0.58
Real World ROUGE: 0.79
Real World Probability: 0.1412390053657359
Real World Truth Ratio: 0.6138701648990748
Real World Token Entropy: 0.9600639474881619
Real World Cosine Similarity: 0.7673189233615995
Real World Entailment Score: 0.63
Retain ROUGE: 0.6025208001847684
Retain Probability: 0.8519892269335207
Retain Truth Ratio: 0.4624454776255766
Retain Token Entropy: 0.9628180826236277
Retain Cosine Similarity: 0.8258711731433869
Retain Entailment Score: 0.49
Forget ROUGE: 0.3505123467438541
Forget Probability: 0.12385594170193484
Forget Truth Ratio: 0.9249978024564802
Forget Token Entropy: 0.9594152411272159
Forget Cosine Similarity: 0.6377833835780621
Forget Entailment Score: 0.2
Model Utility Retain: 0.6461262199662047
Model Utility: 0.5631449982374825
Forget Efficacy: 0.5525701051039337
split: forget01
forget_loss: NPO2+GD1
forget_coeff: 1.0
regularization_coeff: 1.0
learning_rate: 2e-05
epochs: 2
fix_ref_model: 
mask: True
unlearn_step: last
task_id: 1
unlearn_times: 1
