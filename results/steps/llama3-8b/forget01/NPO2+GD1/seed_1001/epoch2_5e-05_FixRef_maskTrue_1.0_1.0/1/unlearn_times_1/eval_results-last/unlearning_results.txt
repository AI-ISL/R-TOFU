Real Authors ROUGE: 0.0025
Real Authors Probability: 0.18080402311296329
Real Authors Truth Ratio: 0.8504600543863083
Real Authors Token Entropy: 0.07253051399439459
Real Authors Cosine Similarity: 0.031437864061445
Real Authors Entailment Score: 0.01
Real World ROUGE: 0.01
Real World Probability: 0.051010386678353586
Real World Truth Ratio: 0.5374168434647572
Real World Token Entropy: 0.08928093308390146
Real World Cosine Similarity: 0.028193209609016775
Real World Entailment Score: 0.01
Retain ROUGE: 0.009918347818081314
Retain Probability: 0.008968425628142537
Retain Truth Ratio: 0.35484118328985775
Retain Token Entropy: 0.04069071494105265
Retain Cosine Similarity: 0.06723886324558408
Retain Entailment Score: 0.006666666666666667
Forget ROUGE: 0.001754926108374384
Forget Probability: 0.0017881076757965554
Forget Truth Ratio: 0.8907324612871887
Forget Token Entropy: 0.014518324650790709
Forget Cosine Similarity: 0.08238278571516275
Forget Entailment Score: 0.0
Model Utility Retain: 0.01482976618618432
Model Utility: 0.014693527568490196
Forget Efficacy: 0.8046683438426955
split: forget01
forget_loss: NPO2+GD1
forget_coeff: 1.0
regularization_coeff: 1.0
learning_rate: 5e-05
epochs: 2
fix_ref_model: 
mask: True
unlearn_step: last
task_id: 1
unlearn_times: 1
