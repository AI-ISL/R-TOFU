Real Authors ROUGE: 0.11199999999999999
Real Authors Probability: 0.6363622899742937
Real Authors Truth Ratio: 0.8985097475965031
Real Authors Token Entropy: 0.9654676450691844
Real Authors Cosine Similarity: 0.11713636456057429
Real Authors Entailment Score: 0.11
Real World ROUGE: 0.25666666666666665
Real World Probability: 0.31360397533237655
Real World Truth Ratio: 0.6249159864206907
Real World Token Entropy: 0.9464720457235921
Real World Cosine Similarity: 0.2344699038565159
Real World Entailment Score: 0.2
Retain ROUGE: 0.03249192314835355
Retain Probability: 0.9476166470288471
Retain Truth Ratio: 0.388326891249287
Retain Token Entropy: 0.9800209735894786
Retain Cosine Similarity: 0.11126592840223262
Retain Entailment Score: 0.04666666666666667
Forget ROUGE: 0.003894249231950844
Forget Probability: 0.35879109653889607
Forget Truth Ratio: 0.901174837448404
Forget Token Entropy: 0.9994215544671006
Forget Cosine Similarity: 0.04324075123295188
Forget Entailment Score: 0.0
Model Utility Retain: 0.09112483106436196
Model Utility: 0.15634909587085788
Forget Efficacy: 0.7385798131095594
split: forget01
forget_loss: IDK1+GD1
forget_coeff: 1.0
regularization_coeff: 1.0
learning_rate: 1e-05
epochs: 8
fix_ref_model: 
mask: True
unlearn_step: last
task_id: 1
unlearn_times: 1
