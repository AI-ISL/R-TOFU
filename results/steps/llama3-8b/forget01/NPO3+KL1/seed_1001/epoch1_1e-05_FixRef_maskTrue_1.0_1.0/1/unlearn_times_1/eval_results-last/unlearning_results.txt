Real Authors ROUGE: 0.6741666666666666
Real Authors Probability: 0.5150756740821533
Real Authors Truth Ratio: 0.9124747087527235
Real Authors Token Entropy: 0.982987319386051
Real Authors Cosine Similarity: 0.7936603736877441
Real Authors Entailment Score: 0.66
Real World ROUGE: 0.8066666666666668
Real World Probability: 0.18203718295317056
Real World Truth Ratio: 0.63998866415505
Real World Token Entropy: 0.9038011853353213
Real World Cosine Similarity: 0.7228508804738522
Real World Entailment Score: 0.63
Retain ROUGE: 0.744431496315908
Retain Probability: 0.9961886416279958
Retain Truth Ratio: 0.480773225782727
Retain Token Entropy: 0.9560692993125053
Retain Cosine Similarity: 0.9001604562004407
Retain Entailment Score: 0.5966666666666667
Forget ROUGE: 0.7061253068645399
Forget Probability: 0.22240021925163211
Forget Truth Ratio: 0.9295966486318311
Forget Token Entropy: 0.9515708743071418
Forget Cosine Similarity: 0.9163480788469315
Forget Entailment Score: 0.5
Model Utility Retain: 0.7263961569684243
Model Utility: 0.6218513179378913
Forget Efficacy: 0.3451059492810131
split: forget01
forget_loss: NPO3+KL1
forget_coeff: 1.0
regularization_coeff: 1.0
learning_rate: 1e-05
epochs: 1
fix_ref_model: 
mask: True
unlearn_step: last
task_id: 1
unlearn_times: 1
