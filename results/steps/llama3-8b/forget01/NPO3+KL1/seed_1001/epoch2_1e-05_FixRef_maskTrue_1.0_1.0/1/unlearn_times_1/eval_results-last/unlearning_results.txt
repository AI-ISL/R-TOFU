Real Authors ROUGE: 0.6741666666666666
Real Authors Probability: 0.512894520913269
Real Authors Truth Ratio: 0.9117879846223108
Real Authors Token Entropy: 0.9854269970221873
Real Authors Cosine Similarity: 0.7813024535775185
Real Authors Entailment Score: 0.66
Real World ROUGE: 0.8133333333333335
Real World Probability: 0.18370677839831434
Real World Truth Ratio: 0.6440168083236708
Real World Token Entropy: 0.939318476920748
Real World Cosine Similarity: 0.7280465627461672
Real World Entailment Score: 0.64
Retain ROUGE: 0.732947222305178
Retain Probability: 0.9851711439269605
Retain Truth Ratio: 0.48376970387906654
Retain Token Entropy: 0.9451157276737934
Retain Cosine Similarity: 0.8972319887081782
Retain Entailment Score: 0.6566666666666666
Forget ROUGE: 0.7026756952174055
Forget Probability: 0.2006197399714364
Forget Truth Ratio: 0.9257427613970632
Forget Token Entropy: 0.9243789983564934
Forget Cosine Similarity: 0.9029302254319191
Forget Entailment Score: 0.475
Model Utility Retain: 0.7369233758645012
Model Utility: 0.6270039980441843
Forget Efficacy: 0.3586063155964351
split: forget01
forget_loss: NPO3+KL1
forget_coeff: 1.0
regularization_coeff: 1.0
learning_rate: 1e-05
epochs: 2
fix_ref_model: 
mask: True
unlearn_step: last
task_id: 1
unlearn_times: 1
