Real Authors ROUGE: 0.6308333333333332
Real Authors Probability: 0.6791987116293694
Real Authors Truth Ratio: 0.9111505033769578
Real Authors Token Entropy: 0.9284079606365572
Real Authors Cosine Similarity: 0.5461265696585178
Real Authors Entailment Score: 0.63
Real World ROUGE: 0.7591666666666668
Real World Probability: 0.287772510244418
Real World Truth Ratio: 0.606172636439516
Real World Token Entropy: 0.8356512689460213
Real World Cosine Similarity: 0.5729435034468771
Real World Entailment Score: 0.62
Retain ROUGE: 0.33307793988943046
Retain Probability: 0.8774891587459687
Retain Truth Ratio: 0.4133313223548545
Retain Token Entropy: 0.9774461704072371
Retain Cosine Similarity: 0.5105680889558668
Retain Entailment Score: 0.35
Forget ROUGE: 0.04210667885106908
Forget Probability: 0.3016153693281744
Forget Truth Ratio: 0.9107381112437457
Forget Token Entropy: 0.9943325137615598
Forget Cosine Similarity: 0.08249736225698143
Forget Entailment Score: 0.0
Model Utility Retain: 0.48386699308963527
Model Utility: 0.5616666561835647
Forget Efficacy: 0.7326084956640059
split: forget01
forget_loss: IDK2+GD1
forget_coeff: 1.0
regularization_coeff: 1.0
learning_rate: 1e-05
epochs: 5
fix_ref_model: 
mask: True
unlearn_step: last
task_id: 1
unlearn_times: 1
