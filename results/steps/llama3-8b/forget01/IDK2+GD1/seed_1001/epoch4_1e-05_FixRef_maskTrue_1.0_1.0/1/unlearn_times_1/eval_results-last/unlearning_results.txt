Real Authors ROUGE: 0.6618333333333334
Real Authors Probability: 0.6759687297600901
Real Authors Truth Ratio: 0.9120187686758321
Real Authors Token Entropy: 0.9662620270273492
Real Authors Cosine Similarity: 0.5993729489296675
Real Authors Entailment Score: 0.65
Real World ROUGE: 0.7966666666666667
Real World Probability: 0.28608689702556606
Real World Truth Ratio: 0.6086886970027485
Real World Token Entropy: 0.8035608084240567
Real World Cosine Similarity: 0.5664729682542383
Real World Entailment Score: 0.62
Retain ROUGE: 0.4239841501596057
Retain Probability: 0.9148439988832471
Retain Truth Ratio: 0.4159828216394881
Retain Token Entropy: 0.9808920265251552
Retain Cosine Similarity: 0.6375529225124046
Retain Entailment Score: 0.45666666666666667
Forget ROUGE: 0.08667337346217706
Forget Probability: 0.3218888667905694
Forget Truth Ratio: 0.9112619400209234
Forget Token Entropy: 0.9906457655520592
Forget Cosine Similarity: 0.20718097793869675
Forget Entailment Score: 0.0
Model Utility Retain: 0.5642616341058159
Model Utility: 0.6004372117240017
Forget Efficacy: 0.6945989683575267
split: forget01
forget_loss: IDK2+GD1
forget_coeff: 1.0
regularization_coeff: 1.0
learning_rate: 1e-05
epochs: 4
fix_ref_model: 
mask: True
unlearn_step: last
task_id: 1
unlearn_times: 1
