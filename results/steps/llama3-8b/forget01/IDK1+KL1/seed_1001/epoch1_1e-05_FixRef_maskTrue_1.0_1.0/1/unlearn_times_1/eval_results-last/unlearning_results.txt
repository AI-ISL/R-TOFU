Real Authors ROUGE: 0.6358333333333333
Real Authors Probability: 0.5755124983146631
Real Authors Truth Ratio: 0.9108962139176104
Real Authors Token Entropy: 0.9732581614056186
Real Authors Cosine Similarity: 0.7973923622071744
Real Authors Entailment Score: 0.6
Real World ROUGE: 0.7775
Real World Probability: 0.23794436776519676
Real World Truth Ratio: 0.6415667129036368
Real World Token Entropy: 0.8705520760658791
Real World Cosine Similarity: 0.6659600621834397
Real World Entailment Score: 0.65
Retain ROUGE: 0.7611095697608726
Retain Probability: 0.9992568369404247
Retain Truth Ratio: 0.45307269745332973
Retain Token Entropy: 0.9551460792690847
Retain Cosine Similarity: 0.9085088314612707
Retain Entailment Score: 0.6266666666666667
Forget ROUGE: 0.7005844330475048
Forget Probability: 0.35612497030317647
Forget Truth Ratio: 0.9183074614834412
Forget Token Entropy: 0.9659391089800888
Forget Cosine Similarity: 0.9019102990627289
Forget Entailment Score: 0.5
Model Utility Retain: 0.7259373524152676
Model Utility: 0.6461381780188655
Forget Efficacy: 0.32461456722062976
split: forget01
forget_loss: IDK1+KL1
forget_coeff: 1.0
regularization_coeff: 1.0
learning_rate: 1e-05
epochs: 1
fix_ref_model: 
mask: True
unlearn_step: last
task_id: 1
unlearn_times: 1
