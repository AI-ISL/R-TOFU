Real Authors ROUGE: 0.6235
Real Authors Probability: 0.41063335797270734
Real Authors Truth Ratio: 0.9051586812650991
Real Authors Token Entropy: 0.9773144992274722
Real Authors Cosine Similarity: 0.634359342418611
Real Authors Entailment Score: 0.58
Real World ROUGE: 0.7375
Real World Probability: 0.12699786805294638
Real World Truth Ratio: 0.6118412011054127
Real World Token Entropy: 0.929526075439308
Real World Cosine Similarity: 0.6499166966974735
Real World Entailment Score: 0.61
Retain ROUGE: 0.40865648972920177
Retain Probability: 0.4882080326058993
Retain Truth Ratio: 0.4742415431703266
Retain Token Entropy: 0.9189135812909186
Retain Cosine Similarity: 0.6574949677102268
Retain Entailment Score: 0.37666666666666665
Forget ROUGE: 0.29945463183097143
Forget Probability: 0.03463733697136869
Forget Truth Ratio: 0.9326923224418884
Forget Token Entropy: 0.8672759537220781
Forget Cosine Similarity: 0.5907918031793088
Forget Entailment Score: 0.2
Model Utility Retain: 0.5055606058539995
Model Utility: 0.49377353676407176
Forget Efficacy: 0.5884847811152925
split: forget01
forget_loss: NPO2+GD2
forget_coeff: 1.0
regularization_coeff: 1.0
learning_rate: 1e-05
epochs: 6
fix_ref_model: 
mask: True
unlearn_step: last
task_id: 1
unlearn_times: 1
