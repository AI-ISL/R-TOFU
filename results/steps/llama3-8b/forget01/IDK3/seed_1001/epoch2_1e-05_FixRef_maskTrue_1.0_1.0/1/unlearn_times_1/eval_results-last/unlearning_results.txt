Real Authors ROUGE: 0.6118333333333333
Real Authors Probability: 0.5826088942245563
Real Authors Truth Ratio: 0.910438110104927
Real Authors Token Entropy: 0.973620947353193
Real Authors Cosine Similarity: 0.7830867267772555
Real Authors Entailment Score: 0.58
Real World ROUGE: 0.7708333333333335
Real World Probability: 0.24796112934552916
Real World Truth Ratio: 0.6442463991411429
Real World Token Entropy: 0.9099585247033448
Real World Cosine Similarity: 0.6868189220875501
Real World Entailment Score: 0.62
Retain ROUGE: 0.760187067150273
Retain Probability: 0.9992117222212075
Retain Truth Ratio: 0.44914504271797645
Retain Token Entropy: 0.9581635474584091
Retain Cosine Similarity: 0.909270795683066
Retain Entailment Score: 0.61
Forget ROUGE: 0.7137724877533114
Forget Probability: 0.3749992285703113
Forget Truth Ratio: 0.915521583023664
Forget Token Entropy: 0.9630897344281604
Forget Cosine Similarity: 0.9058258175849915
Forget Entailment Score: 0.55
Model Utility Retain: 0.7206777258647066
Model Utility: 0.6462458103072323
Forget Efficacy: 0.3079761766135445
split: forget01
forget_loss: IDK3
forget_coeff: 1.0
regularization_coeff: 1.0
learning_rate: 1e-05
epochs: 2
fix_ref_model: 
mask: True
unlearn_step: last
task_id: 1
unlearn_times: 1
