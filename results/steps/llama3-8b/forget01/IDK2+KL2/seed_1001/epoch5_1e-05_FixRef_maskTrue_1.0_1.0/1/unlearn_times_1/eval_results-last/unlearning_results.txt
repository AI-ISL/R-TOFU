Real Authors ROUGE: 0.6718333333333334
Real Authors Probability: 0.6752532040600389
Real Authors Truth Ratio: 0.9109194831215051
Real Authors Token Entropy: 0.9685458261788988
Real Authors Cosine Similarity: 0.5579416662640869
Real Authors Entailment Score: 0.67
Real World ROUGE: 0.74
Real World Probability: 0.28490287098787026
Real World Truth Ratio: 0.6053268286656276
Real World Token Entropy: 0.8132868963622719
Real World Cosine Similarity: 0.5870855193771422
Real World Entailment Score: 0.58
Retain ROUGE: 0.37040184419962163
Retain Probability: 0.8865109953126467
Retain Truth Ratio: 0.413096032966101
Retain Token Entropy: 0.975817187573196
Retain Cosine Similarity: 0.5496913778518017
Retain Entailment Score: 0.38666666666666666
Forget ROUGE: 0.028505080625731722
Forget Probability: 0.31247929720465206
Forget Truth Ratio: 0.910468573170395
Forget Token Entropy: 0.997694590722584
Forget Cosine Similarity: 0.05991087091388181
Forget Entailment Score: 0.0
Model Utility Retain: 0.5137547371440332
Model Utility: 0.5763026831359774
Forget Efficacy: 0.7377272356170679
split: forget01
forget_loss: IDK2+KL2
forget_coeff: 1.0
regularization_coeff: 1.0
learning_rate: 1e-05
epochs: 5
fix_ref_model: 
mask: True
unlearn_step: last
task_id: 1
unlearn_times: 1
