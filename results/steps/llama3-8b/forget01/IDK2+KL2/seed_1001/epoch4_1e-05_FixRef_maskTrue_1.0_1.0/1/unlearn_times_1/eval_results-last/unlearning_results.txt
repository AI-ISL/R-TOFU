Real Authors ROUGE: 0.6518333333333334
Real Authors Probability: 0.6706319093305724
Real Authors Truth Ratio: 0.9128000728444812
Real Authors Token Entropy: 0.9471425804996721
Real Authors Cosine Similarity: 0.5804257539659738
Real Authors Entailment Score: 0.65
Real World ROUGE: 0.7325
Real World Probability: 0.2842541050511586
Real World Truth Ratio: 0.609147642289199
Real World Token Entropy: 0.8435623060093067
Real World Cosine Similarity: 0.5740175050124526
Real World Entailment Score: 0.59
Retain ROUGE: 0.47391170941386707
Retain Probability: 0.9295922556155012
Retain Truth Ratio: 0.4184665496586567
Retain Token Entropy: 0.9750690988296998
Retain Cosine Similarity: 0.6879884022241458
Retain Entailment Score: 0.48
Forget ROUGE: 0.11859740904367669
Forget Probability: 0.32745447043157855
Forget Truth Ratio: 0.911590292628717
Forget Token Entropy: 0.9674874431731117
Forget Cosine Similarity: 0.24085081196390093
Forget Entailment Score: 0.05
Model Utility Retain: 0.5918367975234824
Model Utility: 0.605588699038813
Forget Efficacy: 0.6703014031864254
split: forget01
forget_loss: IDK2+KL2
forget_coeff: 1.0
regularization_coeff: 1.0
learning_rate: 1e-05
epochs: 4
fix_ref_model: 
mask: True
unlearn_step: last
task_id: 1
unlearn_times: 1
