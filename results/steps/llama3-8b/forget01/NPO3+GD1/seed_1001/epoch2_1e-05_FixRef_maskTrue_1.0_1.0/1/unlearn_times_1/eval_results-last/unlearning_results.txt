Real Authors ROUGE: 0.6958333333333333
Real Authors Probability: 0.5164132951044076
Real Authors Truth Ratio: 0.9138707882434944
Real Authors Token Entropy: 0.9854301259864034
Real Authors Cosine Similarity: 0.8116225689649582
Real Authors Entailment Score: 0.66
Real World ROUGE: 0.7975
Real World Probability: 0.185812469835462
Real World Truth Ratio: 0.6463819536001243
Real World Token Entropy: 0.9143389267946936
Real World Cosine Similarity: 0.7084038159996271
Real World Entailment Score: 0.63
Retain ROUGE: 0.7302490403284464
Retain Probability: 0.9847790638844018
Retain Truth Ratio: 0.48249268517382005
Retain Token Entropy: 0.9433983804833622
Retain Cosine Similarity: 0.8899216312170029
Retain Entailment Score: 0.6066666666666667
Forget ROUGE: 0.6798694673880188
Forget Probability: 0.20002198531551169
Forget Truth Ratio: 0.9264944112598776
Forget Token Entropy: 0.9144324428565367
Forget Cosine Similarity: 0.893846583366394
Forget Entailment Score: 0.475
Model Utility Retain: 0.723810194963323
Model Utility: 0.6251154264029095
Forget Efficacy: 0.36495351053403957
split: forget01
forget_loss: NPO3+GD1
forget_coeff: 1.0
regularization_coeff: 1.0
learning_rate: 1e-05
epochs: 2
fix_ref_model: 
mask: True
unlearn_step: last
task_id: 1
unlearn_times: 1
