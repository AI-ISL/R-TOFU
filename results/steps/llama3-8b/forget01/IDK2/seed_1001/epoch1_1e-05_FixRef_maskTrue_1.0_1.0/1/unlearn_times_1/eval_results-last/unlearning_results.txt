Real Authors ROUGE: 0.6625
Real Authors Probability: 0.592545921949595
Real Authors Truth Ratio: 0.9133259751066304
Real Authors Token Entropy: 0.9658750596984069
Real Authors Cosine Similarity: 0.7082282419502736
Real Authors Entailment Score: 0.64
Real World ROUGE: 0.8175
Real World Probability: 0.22183368957491661
Real World Truth Ratio: 0.6245183051701835
Real World Token Entropy: 0.9288885794328788
Real World Cosine Similarity: 0.64755654476583
Real World Entailment Score: 0.66
Retain ROUGE: 0.7266955028955565
Retain Probability: 0.9979645059941826
Retain Truth Ratio: 0.45194248748577387
Retain Token Entropy: 0.9576502735130398
Retain Cosine Similarity: 0.9004806743065517
Retain Entailment Score: 0.6566666666666666
Forget ROUGE: 0.6296787001492753
Forget Probability: 0.30810324156876867
Forget Truth Ratio: 0.9212272289630242
Forget Token Entropy: 0.9666643126814887
Forget Cosine Similarity: 0.8936098322272301
Forget Entailment Score: 0.475
Model Utility Retain: 0.7256555331422075
Model Utility: 0.6419747083946763
Forget Efficacy: 0.3544761994183403
split: forget01
forget_loss: IDK2
forget_coeff: 1.0
regularization_coeff: 1.0
learning_rate: 1e-05
epochs: 1
fix_ref_model: 
mask: True
unlearn_step: last
task_id: 1
unlearn_times: 1
