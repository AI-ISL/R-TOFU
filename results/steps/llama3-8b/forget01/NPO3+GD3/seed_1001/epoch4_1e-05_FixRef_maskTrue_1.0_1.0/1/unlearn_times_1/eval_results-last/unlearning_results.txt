Real Authors ROUGE: 0.6725
Real Authors Probability: 0.3832971621568154
Real Authors Truth Ratio: 0.8881501986057329
Real Authors Token Entropy: 0.6494128346331527
Real Authors Cosine Similarity: 0.6840583016723394
Real Authors Entailment Score: 0.67
Real World ROUGE: 0.7703333333333333
Real World Probability: 0.08779273275426235
Real World Truth Ratio: 0.5652870425681685
Real World Token Entropy: 0.6037856099913299
Real World Cosine Similarity: 0.5996909619867802
Real World Entailment Score: 0.8
Retain ROUGE: 0.6541343256175658
Retain Probability: 0.1085278629316953
Retain Truth Ratio: 0.43415785655542616
Retain Token Entropy: 0.5269094950265927
Retain Cosine Similarity: 0.7720048051079115
Retain Entailment Score: 0.9833333333333333
Forget ROUGE: 0.6420615418844623
Forget Probability: 0.027499724469529585
Forget Truth Ratio: 0.9250743169534617
Forget Token Entropy: 0.5399120316367866
Forget Cosine Similarity: 0.8224295318126679
Forget Entailment Score: 0.975
Model Utility Retain: 0.3476969181130575
Model Utility: 0.3912712823247817
Forget Efficacy: 0.3215869769759757
split: forget01
forget_loss: NPO3+GD3
forget_coeff: 1.0
regularization_coeff: 1.0
learning_rate: 1e-05
epochs: 4
fix_ref_model: 
mask: True
unlearn_step: last
task_id: 1
unlearn_times: 1
