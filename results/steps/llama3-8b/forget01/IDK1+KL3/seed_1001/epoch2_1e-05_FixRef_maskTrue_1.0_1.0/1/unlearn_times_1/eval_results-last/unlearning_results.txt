Real Authors ROUGE: 0.6418333333333334
Real Authors Probability: 0.5890538832957511
Real Authors Truth Ratio: 0.9114960733583038
Real Authors Token Entropy: 0.9842079685956894
Real Authors Cosine Similarity: 0.7764622014760971
Real Authors Entailment Score: 0.61
Real World ROUGE: 0.7833333333333333
Real World Probability: 0.25300209606818314
Real World Truth Ratio: 0.6443002271613243
Real World Token Entropy: 0.8634686513245469
Real World Cosine Similarity: 0.6832193087413907
Real World Entailment Score: 0.62
Retain ROUGE: 0.7575020541020113
Retain Probability: 0.9991677622303001
Retain Truth Ratio: 0.45443492462549157
Retain Token Entropy: 0.9601707562685539
Retain Cosine Similarity: 0.9061943840483825
Retain Entailment Score: 0.6366666666666667
Forget ROUGE: 0.6663422465853668
Forget Probability: 0.37305074220455
Forget Truth Ratio: 0.915465982783783
Forget Token Entropy: 0.962654733749366
Forget Cosine Similarity: 0.8866815969347954
Forget Entailment Score: 0.575
Model Utility Retain: 0.7284051100331076
Model Utility: 0.6533785413642644
Forget Efficacy: 0.31669188629830103
split: forget01
forget_loss: IDK1+KL3
forget_coeff: 1.0
regularization_coeff: 1.0
learning_rate: 1e-05
epochs: 2
fix_ref_model: 
mask: True
unlearn_step: last
task_id: 1
unlearn_times: 1
