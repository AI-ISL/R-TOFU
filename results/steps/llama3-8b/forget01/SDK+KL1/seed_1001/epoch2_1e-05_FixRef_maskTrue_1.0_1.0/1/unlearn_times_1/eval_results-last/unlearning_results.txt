Real Authors ROUGE: 0.6858333333333333
Real Authors Probability: 0.5349930045935555
Real Authors Truth Ratio: 0.9064595922312507
Real Authors Token Entropy: 0.9813674526336079
Real Authors Cosine Similarity: 0.8052290230989456
Real Authors Entailment Score: 0.65
Real World ROUGE: 0.7841666666666667
Real World Probability: 0.20374348138080647
Real World Truth Ratio: 0.6144260965738617
Real World Token Entropy: 0.9353070067570505
Real World Cosine Similarity: 0.7223117892444134
Real World Entailment Score: 0.63
Retain ROUGE: 0.5871727865857818
Retain Probability: 0.9993526757698891
Retain Truth Ratio: 0.4588309533880731
Retain Token Entropy: 0.8541173562519944
Retain Cosine Similarity: 0.7829114990821108
Retain Entailment Score: 0.49333333333333335
Forget ROUGE: 0.3672917472099396
Forget Probability: 0.351876213138591
Forget Truth Ratio: 0.918979164331214
Forget Token Entropy: 0.6716217993663152
Forget Cosine Similarity: 0.6078691027127207
Forget Entailment Score: 0.175
Model Utility Retain: 0.6411430632008088
Model Utility: 0.6114152753173885
Forget Efficacy: 0.515796754521507
split: forget01
forget_loss: SDK+KL1
forget_coeff: 1.0
regularization_coeff: 1.0
learning_rate: 1e-05
epochs: 2
fix_ref_model: 
mask: True
unlearn_step: last
task_id: 1
unlearn_times: 1
