Real Authors ROUGE: 0.1918333333333333
Real Authors Probability: 0.6595170896271517
Real Authors Truth Ratio: 0.9127883211672141
Real Authors Token Entropy: 0.4123783985498046
Real Authors Cosine Similarity: 0.23350962689146398
Real Authors Entailment Score: 0.17
Real World ROUGE: 0.275
Real World Probability: 0.3080195433051196
Real World Truth Ratio: 0.6259525595256603
Real World Token Entropy: 0.4524156798216184
Real World Cosine Similarity: 0.2507490529771894
Real World Entailment Score: 0.21
Retain ROUGE: 0.08186001555116391
Retain Probability: 0.997733838938293
Retain Truth Ratio: 0.43358370703894605
Retain Token Entropy: 0.2077515242510911
Retain Cosine Similarity: 0.2168029313782851
Retain Entailment Score: 0.07
Forget ROUGE: 0.025943935926773454
Forget Probability: 0.40600676331195434
Forget Truth Ratio: 0.9103036618966733
Forget Token Entropy: 0.04937499999999999
Forget Cosine Similarity: 0.12119427416473627
Forget Entailment Score: 0.025
Model Utility Retain: 0.15291982171188406
Model Utility: 0.22758453948514787
Forget Efficacy: 0.7023102729399725
split: forget01
forget_loss: SDK2+GD1
forget_coeff: 1.0
regularization_coeff: 1.0
learning_rate: 1e-05
epochs: 3
fix_ref_model: 
mask: True
unlearn_step: last
task_id: 1
unlearn_times: 1
