Real Authors ROUGE: 0.5891666666666666
Real Authors Probability: 0.4801394691689868
Real Authors Truth Ratio: 0.8992833198675646
Real Authors Token Entropy: 0.9176765284254305
Real Authors Cosine Similarity: 0.7161926262080669
Real Authors Entailment Score: 0.51
Real World ROUGE: 0.805
Real World Probability: 0.17313080489365934
Real World Truth Ratio: 0.6180602976021679
Real World Token Entropy: 0.8975135591026969
Real World Cosine Similarity: 0.6711335195042193
Real World Entailment Score: 0.69
Retain ROUGE: 0.417612864507343
Retain Probability: 0.9886113059899736
Retain Truth Ratio: 0.45603998523649275
Retain Token Entropy: 0.8051533094103924
Retain Cosine Similarity: 0.6961922533856705
Retain Entailment Score: 0.2633333333333333
Forget ROUGE: 0.33032682703688654
Forget Probability: 0.11363238575431389
Forget Truth Ratio: 0.9183724067173464
Forget Token Entropy: 0.7364877537113886
Forget Cosine Similarity: 0.6353968650102615
Forget Entailment Score: 0.1
Model Utility Retain: 0.49690572648532455
Model Utility: 0.5278098684069858
Forget Efficacy: 0.5804543030962384
split: forget01
forget_loss: NPO1+KL1
forget_coeff: 1.0
regularization_coeff: 1.0
learning_rate: 2e-05
epochs: 3
fix_ref_model: 
mask: True
unlearn_step: last
task_id: 1
unlearn_times: 1
