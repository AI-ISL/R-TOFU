Real Authors ROUGE: 0.5506666666666666
Real Authors Probability: 0.5006711276571821
Real Authors Truth Ratio: 0.911610989072112
Real Authors Token Entropy: 0.9626114642976819
Real Authors Cosine Similarity: 0.7538456592708827
Real Authors Entailment Score: 0.54
Real World ROUGE: 0.8336666666666668
Real World Probability: 0.16547787508506073
Real World Truth Ratio: 0.6365258313348099
Real World Token Entropy: 0.9175081754411812
Real World Cosine Similarity: 0.674453062005341
Real World Entailment Score: 0.69
Retain ROUGE: 0.517438098375366
Retain Probability: 0.9956974229237486
Retain Truth Ratio: 0.4616147058576081
Retain Token Entropy: 0.955809192141287
Retain Cosine Similarity: 0.8144951238359014
Retain Entailment Score: 0.3566666666666667
Forget ROUGE: 0.41153624192229427
Forget Probability: 0.06798665094411478
Forget Truth Ratio: 0.9256989632746938
Forget Token Entropy: 0.9328399269145722
Forget Cosine Similarity: 0.7597060281783342
Forget Entailment Score: 0.2
Model Utility Retain: 0.5893356782779157
Model Utility: 0.5599808396103214
Forget Efficacy: 0.5270144231361125
split: forget01
forget_loss: NPO1+KL1
forget_coeff: 1.0
regularization_coeff: 1.0
learning_rate: 1e-05
epochs: 9
fix_ref_model: 
mask: True
unlearn_step: last
task_id: 1
unlearn_times: 1
