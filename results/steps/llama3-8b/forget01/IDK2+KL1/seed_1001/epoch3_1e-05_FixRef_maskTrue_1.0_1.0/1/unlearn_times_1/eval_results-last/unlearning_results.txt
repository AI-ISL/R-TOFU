Real Authors ROUGE: 0.6568333333333334
Real Authors Probability: 0.6497706495962194
Real Authors Truth Ratio: 0.9123693558903205
Real Authors Token Entropy: 0.9695339799255112
Real Authors Cosine Similarity: 0.623098113592714
Real Authors Entailment Score: 0.63
Real World ROUGE: 0.7591666666666668
Real World Probability: 0.26581825263681
Real World Truth Ratio: 0.6133364975539459
Real World Token Entropy: 0.8427764871014611
Real World Cosine Similarity: 0.6008123363927007
Real World Entailment Score: 0.57
Retain ROUGE: 0.579432390428865
Retain Probability: 0.9580092448354102
Retain Truth Ratio: 0.42302779889764536
Retain Token Entropy: 0.9713872546302453
Retain Cosine Similarity: 0.7970130074831346
Retain Entailment Score: 0.57
Forget ROUGE: 0.17989347567905734
Forget Probability: 0.32696774681234325
Forget Truth Ratio: 0.913644760808039
Forget Token Entropy: 0.9928212963096346
Forget Cosine Similarity: 0.3248922677710652
Forget Entailment Score: 0.1
Model Utility Retain: 0.6541580615248626
Model Utility: 0.6235235816708151
Forget Efficacy: 0.6309203497858991
split: forget01
forget_loss: IDK2+KL1
forget_coeff: 1.0
regularization_coeff: 1.0
learning_rate: 1e-05
epochs: 3
fix_ref_model: 
mask: True
unlearn_step: last
task_id: 1
unlearn_times: 1
