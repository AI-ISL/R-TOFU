Real Authors ROUGE: 0.6591666666666666
Real Authors Probability: 0.5137044836444047
Real Authors Truth Ratio: 0.9054619975968804
Real Authors Token Entropy: 0.9805022909552951
Real Authors Cosine Similarity: 0.7974710544943809
Real Authors Entailment Score: 0.63
Real World ROUGE: 0.8066666666666668
Real World Probability: 0.18610998603861093
Real World Truth Ratio: 0.6285865782572391
Real World Token Entropy: 0.9333884865899463
Real World Cosine Similarity: 0.732986313700676
Real World Entailment Score: 0.67
Retain ROUGE: 0.6273279569713426
Retain Probability: 0.9990794448920498
Retain Truth Ratio: 0.46399917090722537
Retain Token Entropy: 0.9590657728673015
Retain Cosine Similarity: 0.8541300288836161
Retain Entailment Score: 0.42333333333333334
Forget ROUGE: 0.5667570466206048
Forget Probability: 0.2724199991963737
Forget Truth Ratio: 0.9383636616526602
Forget Token Entropy: 0.9580750941964954
Forget Cosine Similarity: 0.8536041930317879
Forget Entailment Score: 0.395
Model Utility Retain: 0.6433744927531844
Model Utility: 0.6022687298006715
Forget Efficacy: 0.39477101989971475
split: forget05
forget_loss: NPO1+GD1
forget_coeff: 1.0
regularization_coeff: 1.0
learning_rate: 1e-05
epochs: 1
fix_ref_model: 
mask: True
unlearn_step: last
task_id: 1
unlearn_times: 1
