Real Authors ROUGE: 0.52
Real Authors Probability: 0.5172758433868327
Real Authors Truth Ratio: 0.9252392988502802
Real Authors Token Entropy: 0.6937111187532853
Real Authors Cosine Similarity: 0.5645315596647561
Real Authors Entailment Score: 0.48
Real World ROUGE: 0.7
Real World Probability: 0.20117356214310475
Real World Truth Ratio: 0.6532391179012916
Real World Token Entropy: 0.8559414682833674
Real World Cosine Similarity: 0.6184427840076387
Real World Entailment Score: 0.62
Retain ROUGE: 0.3923999102939722
Retain Probability: 0.9296681837456601
Retain Truth Ratio: 0.45661188056595337
Retain Token Entropy: 0.8002808302870993
Retain Cosine Similarity: 0.667907646059369
Retain Entailment Score: 0.24666666666666667
Forget ROUGE: 0.3314473704193035
Forget Probability: 0.09507347860755277
Forget Truth Ratio: 0.9290565870994856
Forget Token Entropy: 0.7480899108427695
Forget Cosine Similarity: 0.6102380990236997
Forget Entailment Score: 0.12
Model Utility Retain: 0.4756263184948906
Model Utility: 0.5117027505786362
Forget Efficacy: 0.5828368929699916
split: forget05
forget_loss: NPO1+GD1
forget_coeff: 1.0
regularization_coeff: 1.0
learning_rate: 1e-05
epochs: 3
fix_ref_model: 
mask: True
unlearn_step: last
task_id: 1
unlearn_times: 1
