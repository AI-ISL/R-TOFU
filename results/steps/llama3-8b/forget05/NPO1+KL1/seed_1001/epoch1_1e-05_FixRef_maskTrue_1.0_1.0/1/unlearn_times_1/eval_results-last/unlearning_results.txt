Real Authors ROUGE: 0.6066666666666667
Real Authors Probability: 0.5176618595065221
Real Authors Truth Ratio: 0.9077623298791023
Real Authors Token Entropy: 0.982517924133253
Real Authors Cosine Similarity: 0.7928138905391097
Real Authors Entailment Score: 0.6
Real World ROUGE: 0.7683333333333334
Real World Probability: 0.18803034115742726
Real World Truth Ratio: 0.6271707341401278
Real World Token Entropy: 0.9375830730650556
Real World Cosine Similarity: 0.7185646711289883
Real World Entailment Score: 0.64
Retain ROUGE: 0.6471747670298655
Retain Probability: 0.9992082392480331
Retain Truth Ratio: 0.4644619118622645
Retain Token Entropy: 0.960972849575954
Retain Cosine Similarity: 0.8733567475279173
Retain Entailment Score: 0.45666666666666667
Forget ROUGE: 0.584271737350747
Forget Probability: 0.28134184542550034
Forget Truth Ratio: 0.9389675199750847
Forget Token Entropy: 0.9578587254931062
Forget Cosine Similarity: 0.8656623855233192
Forget Entailment Score: 0.46
Model Utility Retain: 0.661200758595148
Model Utility: 0.6012642439812198
Forget Efficacy: 0.3739513023450698
split: forget05
forget_loss: NPO1+KL1
forget_coeff: 1.0
regularization_coeff: 1.0
learning_rate: 1e-05
epochs: 1
fix_ref_model: 
mask: True
unlearn_step: last
task_id: 1
unlearn_times: 1
