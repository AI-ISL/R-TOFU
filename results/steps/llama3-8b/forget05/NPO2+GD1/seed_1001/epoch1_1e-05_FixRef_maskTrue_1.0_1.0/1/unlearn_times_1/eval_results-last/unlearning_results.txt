Real Authors ROUGE: 0.6808333333333333
Real Authors Probability: 0.4585437305673266
Real Authors Truth Ratio: 0.9035333545513987
Real Authors Token Entropy: 0.9643462205712813
Real Authors Cosine Similarity: 0.8168645824491978
Real Authors Entailment Score: 0.66
Real World ROUGE: 0.8266666666666667
Real World Probability: 0.14899172280353462
Real World Truth Ratio: 0.6130343816823867
Real World Token Entropy: 0.9231996454126022
Real World Cosine Similarity: 0.7470699982345104
Real World Entailment Score: 0.7
Retain ROUGE: 0.6797200225949895
Retain Probability: 0.934316587449415
Retain Truth Ratio: 0.477255295006237
Retain Token Entropy: 0.9569759393554853
Retain Cosine Similarity: 0.8755378631254037
Retain Entailment Score: 0.53
Forget ROUGE: 0.621482892691267
Forget Probability: 0.2330900061088143
Forget Truth Ratio: 0.9416896839919525
Forget Token Entropy: 0.9587434123113426
Forget Cosine Similarity: 0.8773732614517212
Forget Entailment Score: 0.53
Model Utility Retain: 0.6888067931889221
Model Utility: 0.587344366139655
Forget Efficacy: 0.359272831151249
split: forget05
forget_loss: NPO2+GD1
forget_coeff: 1.0
regularization_coeff: 1.0
learning_rate: 1e-05
epochs: 1
fix_ref_model: 
mask: True
unlearn_step: last
task_id: 1
unlearn_times: 1
