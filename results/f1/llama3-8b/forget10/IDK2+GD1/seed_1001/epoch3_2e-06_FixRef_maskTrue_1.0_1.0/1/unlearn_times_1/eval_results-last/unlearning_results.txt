Real Authors ROUGE: 0.4946666666666667
Real Authors Probability: 0.4630089471049635
Real Authors Truth Ratio: 0.8872334358933023
Real Authors Token Entropy: 0.9671556978291903
Real Authors Cosine Similarity: 0.5772816632315516
Real Authors Entailment Score: 0.41
Real World ROUGE: 0.7521367521367521
Real World Probability: 0.14126846914637253
Real World Truth Ratio: 0.5772147228533748
Real World Token Entropy: 0.9753863067778079
Real World Cosine Similarity: 0.8045874636333722
Real World Entailment Score: 0.5042735042735043
Retain ROUGE: 0.2711677208729894
Retain Probability: 0.8962135069271483
Retain Truth Ratio: 0.4094865409713634
Retain Token Entropy: 0.9880142694471233
Retain Cosine Similarity: 0.38439108891257395
Retain Entailment Score: 0.2733333333333333
Forget ROUGE: 0.13809566211610247
Forget Probability: 0.34243031290175796
Forget Truth Ratio: 0.9360733138817621
Forget Token Entropy: 0.9794747779200994
Forget Cosine Similarity: 0.24158282010195156
Forget Entailment Score: 0.08
Model Utility Retain: 0.4132849723277039
Model Utility: 0.45658164327256473
Forget Efficacy: 0.6523635781996852
split: forget10
forget_loss: IDK2+GD1
forget_coeff: 1.0
regularization_coeff: 1.0
learning_rate: 2e-06
epochs: 3
fix_ref_model: 
mask: True
unlearn_step: last
task_id: 1
unlearn_times: 1
