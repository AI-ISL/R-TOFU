Real Authors ROUGE: 0.6091666666666666
Real Authors Probability: 0.4323641343936315
Real Authors Truth Ratio: 0.8871212447283423
Real Authors Token Entropy: 0.9749826246467762
Real Authors Cosine Similarity: 0.8202924690395593
Real Authors Entailment Score: 0.5
Real World ROUGE: 0.809116809116809
Real World Probability: 0.1293254867898912
Real World Truth Ratio: 0.575256878563291
Real World Token Entropy: 0.963823486787133
Real World Cosine Similarity: 0.854090455505583
Real World Entailment Score: 0.5555555555555556
Retain ROUGE: 0.6345993762108175
Retain Probability: 0.9816588012878836
Retain Truth Ratio: 0.4181499639209271
Retain Token Entropy: 0.9604755286671843
Retain Cosine Similarity: 0.8616317887386928
Retain Entailment Score: 0.63
Forget ROUGE: 0.6179528090202545
Forget Probability: 0.3441194861394327
Forget Truth Ratio: 0.9381554332120752
Forget Token Entropy: 0.9636597836015507
Forget Cosine Similarity: 0.8657714160283406
Forget Entailment Score: 0.41
Model Utility Retain: 0.6837599968224066
Model Utility: 0.5485044453108916
Forget Efficacy: 0.3648001711199794
split: forget10
forget_loss: IDK2+GD1
forget_coeff: 1.0
regularization_coeff: 1.0
learning_rate: 2e-06
epochs: 2
fix_ref_model: 
mask: True
unlearn_step: last
task_id: 1
unlearn_times: 1
