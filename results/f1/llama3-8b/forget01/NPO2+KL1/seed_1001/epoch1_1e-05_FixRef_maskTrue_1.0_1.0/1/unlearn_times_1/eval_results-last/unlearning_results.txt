Real Authors ROUGE: 0.6768333333333334
Real Authors Probability: 0.29855523865369427
Real Authors Truth Ratio: 0.8739670457631172
Real Authors Token Entropy: 0.9836058178447677
Real Authors Cosine Similarity: 0.846495386660099
Real Authors Entailment Score: 0.56
Real World ROUGE: 0.8126780626780626
Real World Probability: 0.0866269356800102
Real World Truth Ratio: 0.5522693361966845
Real World Token Entropy: 0.9588262986551879
Real World Cosine Similarity: 0.8469108712469411
Real World Entailment Score: 0.5128205128205128
Retain ROUGE: 0.7326275641085742
Retain Probability: 0.9966389802216179
Retain Truth Ratio: 0.4646900000936741
Retain Token Entropy: 0.9604015296806097
Retain Cosine Similarity: 0.899239753584067
Retain Entailment Score: 0.6
Forget ROUGE: 0.6364962049057562
Forget Probability: 0.2609549687210178
Forget Truth Ratio: 0.9238745725113557
Forget Token Entropy: 0.9668303067526743
Forget Cosine Similarity: 0.8901429533958435
Forget Entailment Score: 0.475
Model Utility Retain: 0.7194035034034931
Model Utility: 0.48578047845611394
Forget Efficacy: 0.3627062600932053
split: forget01
forget_loss: NPO2+KL1
forget_coeff: 1.0
regularization_coeff: 1.0
learning_rate: 1e-05
epochs: 1
fix_ref_model: 
mask: True
unlearn_step: last
task_id: 1
unlearn_times: 1
