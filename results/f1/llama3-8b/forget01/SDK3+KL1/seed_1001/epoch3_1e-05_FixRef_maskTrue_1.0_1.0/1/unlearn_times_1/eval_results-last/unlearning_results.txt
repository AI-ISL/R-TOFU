Real Authors ROUGE: 0.111
Real Authors Probability: 0.40592136087245373
Real Authors Truth Ratio: 0.8792411052609884
Real Authors Token Entropy: 0.18430489927351254
Real Authors Cosine Similarity: 0.19023012488149108
Real Authors Entailment Score: 0.1
Real World ROUGE: 0.22079772079772078
Real World Probability: 0.12598193234709626
Real World Truth Ratio: 0.5647749778772213
Real World Token Entropy: 0.24808095984035214
Real World Cosine Similarity: 0.23625573613004297
Real World Entailment Score: 0.17094017094017094
Retain ROUGE: 0.03367129319599115
Retain Probability: 0.9986916984429748
Retain Truth Ratio: 0.43334883540881663
Retain Token Entropy: 0.07035964013085963
Retain Cosine Similarity: 0.1388309023436159
Retain Entailment Score: 0.03
Forget ROUGE: 0.011607142857142858
Forget Probability: 0.4125706737185567
Forget Truth Ratio: 0.9087314862698876
Forget Token Entropy: 0.023902463040016614
Forget Cosine Similarity: 0.09822252430021763
Forget Entailment Score: 0.0
Model Utility Retain: 0.06837073669818522
Model Utility: 0.12048172679264413
Forget Efficacy: 0.713773634570839
split: forget01
forget_loss: SDK3+KL1
forget_coeff: 1.0
regularization_coeff: 1.0
learning_rate: 1e-05
epochs: 3
fix_ref_model: 
mask: True
unlearn_step: last
task_id: 1
unlearn_times: 1
