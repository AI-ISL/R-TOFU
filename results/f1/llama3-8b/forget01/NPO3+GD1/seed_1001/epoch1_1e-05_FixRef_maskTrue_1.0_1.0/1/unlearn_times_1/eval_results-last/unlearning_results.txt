Real Authors ROUGE: 0.6058333333333333
Real Authors Probability: 0.27531085765894703
Real Authors Truth Ratio: 0.8711658564274913
Real Authors Token Entropy: 0.9727618575411598
Real Authors Cosine Similarity: 0.8148368525505066
Real Authors Entailment Score: 0.46
Real World ROUGE: 0.8148148148148148
Real World Probability: 0.08125002155242782
Real World Truth Ratio: 0.5478635364264645
Real World Token Entropy: 0.9440069459638368
Real World Cosine Similarity: 0.8552179881650158
Real World Entailment Score: 0.49572649572649574
Retain ROUGE: 0.7259192017625764
Retain Probability: 0.9962069550146971
Retain Truth Ratio: 0.4730190402140416
Retain Token Entropy: 0.9507554426463594
Retain Cosine Similarity: 0.8988540913164615
Retain Entailment Score: 0.58
Forget ROUGE: 0.7421013052243989
Forget Probability: 0.2518532457246411
Forget Truth Ratio: 0.9230697748685791
Forget Token Entropy: 0.9445909289999112
Forget Cosine Similarity: 0.9276839062571526
Forget Entailment Score: 0.6
Model Utility Retain: 0.7156563829953739
Model Utility: 0.46332152506205043
Forget Efficacy: 0.31105835358504563
split: forget01
forget_loss: NPO3+GD1
forget_coeff: 1.0
regularization_coeff: 1.0
learning_rate: 1e-05
epochs: 1
fix_ref_model: 
mask: True
unlearn_step: last
task_id: 1
unlearn_times: 1
