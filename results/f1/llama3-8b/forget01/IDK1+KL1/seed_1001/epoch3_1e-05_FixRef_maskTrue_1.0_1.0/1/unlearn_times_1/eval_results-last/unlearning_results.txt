Real Authors ROUGE: 0.44433333333333336
Real Authors Probability: 0.40181017122056284
Real Authors Truth Ratio: 0.8802923508860984
Real Authors Token Entropy: 0.8376402767964545
Real Authors Cosine Similarity: 0.6642538282833993
Real Authors Entailment Score: 0.35
Real World ROUGE: 0.7143874643874645
Real World Probability: 0.12094667511748834
Real World Truth Ratio: 0.5774537997782295
Real World Token Entropy: 0.9266219308824215
Real World Cosine Similarity: 0.8229419705577385
Real World Entailment Score: 0.4700854700854701
Retain ROUGE: 0.5365258252625231
Retain Probability: 0.9951738035211372
Retain Truth Ratio: 0.4207482879163148
Retain Token Entropy: 0.934780541305052
Retain Cosine Similarity: 0.7878342344984413
Retain Entailment Score: 0.48333333333333334
Forget ROUGE: 0.36890185292928185
Forget Probability: 0.4291033300412167
Forget Truth Ratio: 0.9055487684259328
Forget Token Entropy: 0.9032311003912297
Forget Cosine Similarity: 0.6672276756260545
Forget Entailment Score: 0.175
Model Utility Retain: 0.6215395408800779
Model Utility: 0.4877200532217671
Forget Efficacy: 0.49084367459550293
split: forget01
forget_loss: IDK1+KL1
forget_coeff: 1.0
regularization_coeff: 1.0
learning_rate: 1e-05
epochs: 3
fix_ref_model: 
mask: True
unlearn_step: last
task_id: 1
unlearn_times: 1
