Real Authors ROUGE: 0.5718333333333334
Real Authors Probability: 0.27354485035710296
Real Authors Truth Ratio: 0.871009589241661
Real Authors Token Entropy: 0.9742459716338981
Real Authors Cosine Similarity: 0.7881285613402724
Real Authors Entailment Score: 0.47
Real World ROUGE: 0.7834757834757835
Real World Probability: 0.08176835026726927
Real World Truth Ratio: 0.5443493136506816
Real World Token Entropy: 0.9376824819195615
Real World Cosine Similarity: 0.8274568188298717
Real World Entailment Score: 0.4700854700854701
Retain ROUGE: 0.6176692045043676
Retain Probability: 0.9517511546555791
Retain Truth Ratio: 0.4745896334314772
Retain Token Entropy: 0.961375646824309
Retain Cosine Similarity: 0.8486293986439705
Retain Entailment Score: 0.5166666666666667
Forget ROUGE: 0.45254406250895957
Forget Probability: 0.15223678369410223
Forget Truth Ratio: 0.9244249684529093
Forget Token Entropy: 0.9593474261859429
Forget Cosine Similarity: 0.780171196628362
Forget Entailment Score: 0.35
Model Utility Retain: 0.671832416656305
Model Utility: 0.4539536230143081
Forget Efficacy: 0.4681245977431334
split: forget01
forget_loss: NPO2
forget_coeff: 1.0
regularization_coeff: 1.0
learning_rate: 1e-05
epochs: 4
fix_ref_model: 
mask: True
unlearn_step: last
task_id: 1
unlearn_times: 1
