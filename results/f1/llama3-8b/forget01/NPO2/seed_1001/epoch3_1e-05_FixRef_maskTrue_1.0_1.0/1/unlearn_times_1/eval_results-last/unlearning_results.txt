Real Authors ROUGE: 0.6458333333333333
Real Authors Probability: 0.27669136227196345
Real Authors Truth Ratio: 0.8709407129017959
Real Authors Token Entropy: 0.9849640966467264
Real Authors Cosine Similarity: 0.8185217273235321
Real Authors Entailment Score: 0.51
Real World ROUGE: 0.7606837606837606
Real World Probability: 0.08194486818051613
Real World Truth Ratio: 0.5471101658614842
Real World Token Entropy: 0.9698882234560021
Real World Cosine Similarity: 0.8551909182316217
Real World Entailment Score: 0.49572649572649574
Retain ROUGE: 0.6556758662953105
Retain Probability: 0.975123551613284
Retain Truth Ratio: 0.47315498111803433
Retain Token Entropy: 0.9610066861897678
Retain Cosine Similarity: 0.871143875271082
Retain Entailment Score: 0.5233333333333333
Forget ROUGE: 0.4933489274291711
Forget Probability: 0.17604301671052602
Forget Truth Ratio: 0.9250378957784783
Forget Token Entropy: 0.9557872191159131
Forget Cosine Similarity: 0.826782512664795
Forget Entailment Score: 0.375
Model Utility Retain: 0.6846621099480336
Model Utility: 0.4634963911149833
Forget Efficacy: 0.44075752948340585
split: forget01
forget_loss: NPO2
forget_coeff: 1.0
regularization_coeff: 1.0
learning_rate: 1e-05
epochs: 3
fix_ref_model: 
mask: True
unlearn_step: last
task_id: 1
unlearn_times: 1
