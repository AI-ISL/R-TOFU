Real Authors ROUGE: 0.39799999999999996
Real Authors Probability: 0.427739142828377
Real Authors Truth Ratio: 0.8814243899061113
Real Authors Token Entropy: 0.967658829121562
Real Authors Cosine Similarity: 0.5832920772302895
Real Authors Entailment Score: 0.35
Real World ROUGE: 0.6868945868945868
Real World Probability: 0.13367570788390487
Real World Truth Ratio: 0.5805680229243589
Real World Token Entropy: 0.9648779277908679
Real World Cosine Similarity: 0.8007911163517553
Real World Entailment Score: 0.47863247863247865
Retain ROUGE: 0.30110307169539186
Retain Probability: 0.9873697731360048
Retain Truth Ratio: 0.4105721915169083
Retain Token Entropy: 0.9556094243809574
Retain Cosine Similarity: 0.5474583246946956
Retain Entailment Score: 0.24666666666666667
Forget ROUGE: 0.05926304859113372
Forget Probability: 0.4134055122297296
Forget Truth Ratio: 0.9038217045960263
Forget Token Entropy: 0.9461806663371022
Forget Cosine Similarity: 0.19726442352402956
Forget Entailment Score: 0.0
Model Utility Retain: 0.4380627246637388
Model Utility: 0.44642719012852716
Forget Efficacy: 0.6852490622118161
split: forget01
forget_loss: IDK1+GD1
forget_coeff: 1.0
regularization_coeff: 1.0
learning_rate: 1e-05
epochs: 5
fix_ref_model: 
mask: True
unlearn_step: last
task_id: 1
unlearn_times: 1
