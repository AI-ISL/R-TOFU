Real Authors ROUGE: 0.6258333333333332
Real Authors Probability: 0.3443916534310024
Real Authors Truth Ratio: 0.8770105446698585
Real Authors Token Entropy: 0.9737247802924272
Real Authors Cosine Similarity: 0.8217769471555948
Real Authors Entailment Score: 0.53
Real World ROUGE: 0.8361823361823362
Real World Probability: 0.09982176878994109
Real World Truth Ratio: 0.563718342303653
Real World Token Entropy: 0.9609795470249937
Real World Cosine Similarity: 0.8530308258297861
Real World Entailment Score: 0.5128205128205128
Retain ROUGE: 0.7205494612318634
Retain Probability: 0.9991436894686482
Retain Truth Ratio: 0.4451384562972507
Retain Token Entropy: 0.9587874853881387
Retain Cosine Similarity: 0.8961302900314331
Retain Entailment Score: 0.6033333333333334
Forget ROUGE: 0.6442890950287449
Forget Probability: 0.37726067167945826
Forget Truth Ratio: 0.9147133412996442
Forget Token Entropy: 0.9633950522795066
Forget Cosine Similarity: 0.9022793658077717
Forget Entailment Score: 0.575
Model Utility Retain: 0.7099305788630625
Model Utility: 0.508840289793248
Forget Efficacy: 0.3172915052368761
split: forget01
forget_loss: IDK1+GD1
forget_coeff: 1.0
regularization_coeff: 1.0
learning_rate: 1e-05
epochs: 2
fix_ref_model: 
mask: True
unlearn_step: last
task_id: 1
unlearn_times: 1
