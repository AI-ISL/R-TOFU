Real Authors ROUGE: 0.5985
Real Authors Probability: 0.1889660948835047
Real Authors Truth Ratio: 0.8426178418915141
Real Authors Token Entropy: 0.578970202519104
Real Authors Cosine Similarity: 0.7212159988284111
Real Authors Entailment Score: 0.6
Real World ROUGE: 0.8219373219373218
Real World Probability: 0.05570064178235585
Real World Truth Ratio: 0.5010654146142379
Real World Token Entropy: 0.4935900200794266
Real World Cosine Similarity: 0.7137305509840322
Real World Entailment Score: 0.8461538461538461
Retain ROUGE: 0.6482863250040466
Retain Probability: 0.10457682594381153
Retain Truth Ratio: 0.4282837859219398
Retain Token Entropy: 0.5541505269003536
Retain Cosine Similarity: 0.7799167803923289
Retain Entailment Score: 0.9766666666666667
Forget ROUGE: 0.60438908641345
Forget Probability: 0.03722780633685061
Forget Truth Ratio: 0.9215786863366308
Forget Token Entropy: 0.5541094391148326
Forget Cosine Similarity: 0.7946653150022029
Forget Entailment Score: 0.925
Model Utility Retain: 0.3418721717556916
Model Utility: 0.31997273201871934
Forget Efficacy: 0.3434278211821731
split: forget01
forget_loss: NPO3+KL1
forget_coeff: 1.0
regularization_coeff: 1.0
learning_rate: 1e-05
epochs: 5
fix_ref_model: 
mask: True
unlearn_step: last
task_id: 1
unlearn_times: 1
