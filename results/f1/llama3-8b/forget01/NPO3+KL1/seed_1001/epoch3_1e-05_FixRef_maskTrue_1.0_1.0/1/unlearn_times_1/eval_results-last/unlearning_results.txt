Real Authors ROUGE: 0.6168333333333333
Real Authors Probability: 0.21396936714852813
Real Authors Truth Ratio: 0.8544161480157108
Real Authors Token Entropy: 0.7298086926300554
Real Authors Cosine Similarity: 0.7572365519404411
Real Authors Entailment Score: 0.63
Real World ROUGE: 0.8112535612535612
Real World Probability: 0.06339189734221204
Real World Truth Ratio: 0.5257674676332621
Real World Token Entropy: 0.6428959215870199
Real World Cosine Similarity: 0.7715331463732271
Real World Entailment Score: 0.8205128205128205
Retain ROUGE: 0.6959207824366691
Retain Probability: 0.21661300954836724
Retain Truth Ratio: 0.4377413247453889
Retain Token Entropy: 0.6733854893348002
Retain Cosine Similarity: 0.8081360858678818
Retain Entailment Score: 0.94
Forget ROUGE: 0.6892097358263714
Forget Probability: 0.059018342215975836
Forget Truth Ratio: 0.9231673073381548
Forget Token Entropy: 0.6464942610790543
Forget Cosine Similarity: 0.823727871477604
Forget Entailment Score: 0.725
Model Utility Retain: 0.49487777347332096
Model Utility: 0.38422687916227505
Forget Efficacy: 0.35597534862837876
split: forget01
forget_loss: NPO3+KL1
forget_coeff: 1.0
regularization_coeff: 1.0
learning_rate: 1e-05
epochs: 3
fix_ref_model: 
mask: True
unlearn_step: last
task_id: 1
unlearn_times: 1
