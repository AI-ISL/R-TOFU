Real Authors ROUGE: 0.6376666666666666
Real Authors Probability: 0.28971407237161395
Real Authors Truth Ratio: 0.8765885937200527
Real Authors Token Entropy: 0.977332572232855
Real Authors Cosine Similarity: 0.8248844096064567
Real Authors Entailment Score: 0.54
Real World ROUGE: 0.7777777777777778
Real World Probability: 0.08554306110925343
Real World Truth Ratio: 0.5554368380128243
Real World Token Entropy: 0.9481052507968412
Real World Cosine Similarity: 0.8359833525286781
Real World Entailment Score: 0.4700854700854701
Retain ROUGE: 0.4884666141925856
Retain Probability: 0.9979321379242773
Retain Truth Ratio: 0.4628186021947823
Retain Token Entropy: 0.9367663395176182
Retain Cosine Similarity: 0.7898040187855562
Retain Entailment Score: 0.30333333333333334
Forget ROUGE: 0.4334278977684363
Forget Probability: 0.17086631097810923
Forget Truth Ratio: 0.9221119650369111
Forget Token Entropy: 0.9398383350594838
Forget Cosine Similarity: 0.7900721681304276
Forget Entailment Score: 0.25
Model Utility Retain: 0.5534896578407498
Model Utility: 0.44728663095278837
Forget Efficacy: 0.48670433161722315
split: forget01
forget_loss: NPO1
forget_coeff: 1.0
regularization_coeff: 1.0
learning_rate: 1e-05
epochs: 5
fix_ref_model: 
mask: True
unlearn_step: last
task_id: 1
unlearn_times: 1
