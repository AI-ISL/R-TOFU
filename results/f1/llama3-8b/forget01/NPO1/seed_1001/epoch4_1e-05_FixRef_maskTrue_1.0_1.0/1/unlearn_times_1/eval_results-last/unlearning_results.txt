Real Authors ROUGE: 0.6753333333333333
Real Authors Probability: 0.2905840062165619
Real Authors Truth Ratio: 0.8763836567549212
Real Authors Token Entropy: 0.9840016970997638
Real Authors Cosine Similarity: 0.835578253865242
Real Authors Entailment Score: 0.46
Real World ROUGE: 0.784900284900285
Real World Probability: 0.08527020918359166
Real World Truth Ratio: 0.5555400034488029
Real World Token Entropy: 0.9537992054332356
Real World Cosine Similarity: 0.84942325271475
Real World Entailment Score: 0.4188034188034188
Retain ROUGE: 0.5126827058927789
Retain Probability: 0.9984276906785359
Retain Truth Ratio: 0.46309342131326614
Retain Token Entropy: 0.948958654811918
Retain Cosine Similarity: 0.8019435984517137
Retain Entailment Score: 0.36
Forget ROUGE: 0.4056842978146541
Forget Probability: 0.18433305574463937
Forget Truth Ratio: 0.92426893140563
Forget Token Entropy: 0.9169341544503447
Forget Cosine Similarity: 0.762531572394073
Forget Entailment Score: 0.3
Model Utility Retain: 0.5888110937761235
Model Utility: 0.4493808938367852
Forget Efficacy: 0.48463642852820077
split: forget01
forget_loss: NPO1
forget_coeff: 1.0
regularization_coeff: 1.0
learning_rate: 1e-05
epochs: 4
fix_ref_model: 
mask: True
unlearn_step: last
task_id: 1
unlearn_times: 1
