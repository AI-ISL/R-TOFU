Real Authors ROUGE: 0.6128333333333333
Real Authors Probability: 0.35104108336228185
Real Authors Truth Ratio: 0.8837808825695035
Real Authors Token Entropy: 0.9737993654610656
Real Authors Cosine Similarity: 0.8223880338668823
Real Authors Entailment Score: 0.49
Real World ROUGE: 0.784900284900285
Real World Probability: 0.1002938039566326
Real World Truth Ratio: 0.5669402085295294
Real World Token Entropy: 0.9716261407254632
Real World Cosine Similarity: 0.8545907231477591
Real World Entailment Score: 0.5555555555555556
Retain ROUGE: 0.7234556351913526
Retain Probability: 0.9988051306504023
Retain Truth Ratio: 0.447919304700351
Retain Token Entropy: 0.9584959854409828
Retain Cosine Similarity: 0.9033208358784517
Retain Entailment Score: 0.6833333333333333
Forget ROUGE: 0.7457260357548654
Forget Probability: 0.32798508838577173
Forget Truth Ratio: 0.9216418222980494
Forget Token Entropy: 0.9639919780282694
Forget Cosine Similarity: 0.9370237097144127
Forget Entailment Score: 0.725
Model Utility Retain: 0.7290632834188516
Model Utility: 0.512334038998776
Forget Efficacy: 0.2685246687693801
split: forget01
forget_loss: IDK2+GD1
forget_coeff: 1.0
regularization_coeff: 1.0
learning_rate: 1e-05
epochs: 1
fix_ref_model: 
mask: True
unlearn_step: last
task_id: 1
unlearn_times: 1
