Real Authors ROUGE: 0.6291666666666667
Real Authors Probability: 0.4422111123780686
Real Authors Truth Ratio: 0.8895398776003836
Real Authors Token Entropy: 0.9755617831523634
Real Authors Cosine Similarity: 0.8116929853707552
Real Authors Entailment Score: 0.54
Real World ROUGE: 0.782051282051282
Real World Probability: 0.131736494715815
Real World Truth Ratio: 0.5816672165006705
Real World Token Entropy: 0.9591859219076072
Real World Cosine Similarity: 0.8442856785323885
Real World Entailment Score: 0.5641025641025641
Retain ROUGE: 0.5771085782654339
Retain Probability: 0.9696420728738796
Retain Truth Ratio: 0.4179262250565358
Retain Token Entropy: 0.9609925775198436
Retain Cosine Similarity: 0.8233224787997703
Retain Entailment Score: 0.59
Forget ROUGE: 0.1693348907840518
Forget Probability: 0.34745804533692254
Forget Truth Ratio: 0.9124576308674539
Forget Token Entropy: 0.9790919540939995
Forget Cosine Similarity: 0.3695550085045397
Forget Entailment Score: 0.125
Model Utility Retain: 0.6588376037242928
Model Utility: 0.549127136488312
Forget Efficacy: 0.6152388849014063
split: forget01
forget_loss: IDK2+GD1
forget_coeff: 1.0
regularization_coeff: 1.0
learning_rate: 1e-05
epochs: 3
fix_ref_model: 
mask: True
unlearn_step: last
task_id: 1
unlearn_times: 1
