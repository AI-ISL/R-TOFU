Real Authors ROUGE: 0.6673333333333332
Real Authors Probability: 0.29176725493888517
Real Authors Truth Ratio: 0.8762703378768836
Real Authors Token Entropy: 0.985729630930373
Real Authors Cosine Similarity: 0.8324494621157646
Real Authors Entailment Score: 0.52
Real World ROUGE: 0.7834757834757835
Real World Probability: 0.08597964727693416
Real World Truth Ratio: 0.5563007569481965
Real World Token Entropy: 0.95391803241353
Real World Cosine Similarity: 0.8443201997787015
Real World Entailment Score: 0.4700854700854701
Retain ROUGE: 0.5177149495889627
Retain Probability: 0.9984250589716366
Retain Truth Ratio: 0.4627808993439691
Retain Token Entropy: 0.9493446512764471
Retain Cosine Similarity: 0.8099481675152977
Retain Entailment Score: 0.32
Forget ROUGE: 0.44229817216833284
Forget Probability: 0.18508336398985994
Forget Truth Ratio: 0.9221542243418822
Forget Token Entropy: 0.9443972556297379
Forget Cosine Similarity: 0.7801735242828727
Forget Entailment Score: 0.225
Model Utility Retain: 0.5710480259384401
Model Utility: 0.4525171953472532
Forget Efficacy: 0.48905814304341044
split: forget01
forget_loss: NPO1+KL1
forget_coeff: 1.0
regularization_coeff: 1.0
learning_rate: 1e-05
epochs: 4
fix_ref_model: 
mask: True
unlearn_step: last
task_id: 1
unlearn_times: 1
