Real Authors ROUGE: 0.6485
Real Authors Probability: 0.30347813073598384
Real Authors Truth Ratio: 0.8746756705220534
Real Authors Token Entropy: 0.9845255881619938
Real Authors Cosine Similarity: 0.8284656193852424
Real Authors Entailment Score: 0.5
Real World ROUGE: 0.7799145299145299
Real World Probability: 0.08828298143670953
Real World Truth Ratio: 0.5553721654589127
Real World Token Entropy: 0.9671055041894804
Real World Cosine Similarity: 0.8494801139220213
Real World Entailment Score: 0.47863247863247865
Retain ROUGE: 0.7578967046655388
Retain Probability: 0.9993328406674628
Retain Truth Ratio: 0.4632310218155319
Retain Token Entropy: 0.963076931906321
Retain Cosine Similarity: 0.9160776663819948
Retain Entailment Score: 0.6033333333333334
Forget ROUGE: 0.5520833864558349
Forget Probability: 0.28728430425276813
Forget Truth Ratio: 0.9251021671160491
Forget Token Entropy: 0.9649514860751784
Forget Cosine Similarity: 0.8578546568751335
Forget Entailment Score: 0.45
Model Utility Retain: 0.7258415960041248
Model Utility: 0.484131861050079
Forget Efficacy: 0.38553509706004285
split: forget01
forget_loss: NPO1+KL1
forget_coeff: 1.0
regularization_coeff: 1.0
learning_rate: 1e-05
epochs: 1
fix_ref_model: 
mask: True
unlearn_step: last
task_id: 1
unlearn_times: 1
