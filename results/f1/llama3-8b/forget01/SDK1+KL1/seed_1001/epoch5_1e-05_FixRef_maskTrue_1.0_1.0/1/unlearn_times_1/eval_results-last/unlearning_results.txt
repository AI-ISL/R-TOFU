Real Authors ROUGE: 0.04
Real Authors Probability: 0.4277223555631102
Real Authors Truth Ratio: 0.877553172873381
Real Authors Token Entropy: 0.03954131150428492
Real Authors Cosine Similarity: 0.08069455700926483
Real Authors Entailment Score: 0.03
Real World ROUGE: 0.05413105413105413
Real World Probability: 0.1367275766950528
Real World Truth Ratio: 0.5624128065021239
Real World Token Entropy: 0.057336515102572434
Real World Cosine Similarity: 0.06445352624082921
Real World Entailment Score: 0.05982905982905983
Retain ROUGE: 0.006515669515669516
Retain Probability: 0.9969076875813478
Retain Truth Ratio: 0.4249307387839476
Retain Token Entropy: 0.009592572048852057
Retain Cosine Similarity: 0.09297496994026005
Retain Entailment Score: 0.0033333333333333335
Forget ROUGE: 0.0
Forget Probability: 0.40942388895840587
Forget Truth Ratio: 0.9060052084905222
Forget Token Entropy: 0.0
Forget Cosine Similarity: 0.08071390669792891
Forget Entailment Score: 0.0
Model Utility Retain: 0.010492527885716427
Model Utility: 0.024046022897445497
Forget Efficacy: 0.7207713991706286
split: forget01
forget_loss: SDK1+KL1
forget_coeff: 1.0
regularization_coeff: 1.0
learning_rate: 1e-05
epochs: 5
fix_ref_model: 
mask: True
unlearn_step: last
task_id: 1
unlearn_times: 1
