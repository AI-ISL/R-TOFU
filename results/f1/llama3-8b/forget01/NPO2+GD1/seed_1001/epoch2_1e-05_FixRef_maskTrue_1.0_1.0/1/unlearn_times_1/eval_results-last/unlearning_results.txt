Real Authors ROUGE: 0.6185
Real Authors Probability: 0.29091493997099716
Real Authors Truth Ratio: 0.8735628746544633
Real Authors Token Entropy: 0.9839837671385132
Real Authors Cosine Similarity: 0.8238805025815964
Real Authors Entailment Score: 0.48
Real World ROUGE: 0.782051282051282
Real World Probability: 0.084929588498096
Real World Truth Ratio: 0.5490685895140875
Real World Token Entropy: 0.9511775903638934
Real World Cosine Similarity: 0.845596871107944
Real World Entailment Score: 0.5042735042735043
Retain ROUGE: 0.7179825168034076
Retain Probability: 0.9979692552509813
Retain Truth Ratio: 0.46742527011585255
Retain Token Entropy: 0.9637148407025116
Retain Cosine Similarity: 0.8999271667003632
Retain Entailment Score: 0.5966666666666667
Forget ROUGE: 0.6448398979854976
Forget Probability: 0.24194581870099685
Forget Truth Ratio: 0.923567299053094
Forget Token Entropy: 0.9661593236475422
Forget Cosine Similarity: 0.8995842784643173
Forget Entailment Score: 0.525
Model Utility Retain: 0.7177861266365281
Model Utility: 0.47414853387246175
Forget Efficacy: 0.3530125411592189
split: forget01
forget_loss: NPO2+GD1
forget_coeff: 1.0
regularization_coeff: 1.0
learning_rate: 1e-05
epochs: 2
fix_ref_model: 
mask: True
unlearn_step: last
task_id: 1
unlearn_times: 1
