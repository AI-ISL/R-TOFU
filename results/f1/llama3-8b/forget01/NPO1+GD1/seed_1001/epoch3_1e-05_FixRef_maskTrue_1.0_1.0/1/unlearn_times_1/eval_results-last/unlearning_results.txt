Real Authors ROUGE: 0.6703333333333333
Real Authors Probability: 0.2923537630148439
Real Authors Truth Ratio: 0.8759316862104347
Real Authors Token Entropy: 0.9732928132247061
Real Authors Cosine Similarity: 0.8215362353622914
Real Authors Entailment Score: 0.47
Real World ROUGE: 0.7977207977207976
Real World Probability: 0.0857230579390647
Real World Truth Ratio: 0.5539836642315664
Real World Token Entropy: 0.9400466686120431
Real World Cosine Similarity: 0.8413938519059339
Real World Entailment Score: 0.48717948717948717
Retain ROUGE: 0.5306415588396631
Retain Probability: 0.9989139888211332
Retain Truth Ratio: 0.4635918356293795
Retain Token Entropy: 0.958147901187474
Retain Cosine Similarity: 0.8207841970523199
Retain Entailment Score: 0.38666666666666666
Forget ROUGE: 0.4413701545111716
Forget Probability: 0.20636513840964246
Forget Truth Ratio: 0.9241681936135449
Forget Token Entropy: 0.9616765195636587
Forget Cosine Similarity: 0.7952456027269363
Forget Entailment Score: 0.175
Model Utility Retain: 0.6066180497546314
Model Utility: 0.457476907806732
Forget Efficacy: 0.49157018214774095
split: forget01
forget_loss: NPO1+GD1
forget_coeff: 1.0
regularization_coeff: 1.0
learning_rate: 1e-05
epochs: 3
fix_ref_model: 
mask: True
unlearn_step: last
task_id: 1
unlearn_times: 1
