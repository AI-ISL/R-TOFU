Real Authors ROUGE: 0.6915
Real Authors Probability: 0.2977010620237944
Real Authors Truth Ratio: 0.8733912938624969
Real Authors Token Entropy: 0.9834267146607852
Real Authors Cosine Similarity: 0.8404422751069069
Real Authors Entailment Score: 0.49
Real World ROUGE: 0.7713675213675214
Real World Probability: 0.08612791324376767
Real World Truth Ratio: 0.5510696395737519
Real World Token Entropy: 0.9400686089925112
Real World Cosine Similarity: 0.834868238777177
Real World Entailment Score: 0.48717948717948717
Retain ROUGE: 0.7472421405158197
Retain Probability: 0.9994312597252273
Retain Truth Ratio: 0.4654876769888547
Retain Token Entropy: 0.959252698435705
Retain Cosine Similarity: 0.9140730005999406
Retain Entailment Score: 0.64
Forget ROUGE: 0.6824267383105445
Forget Probability: 0.27754604333211425
Forget Truth Ratio: 0.9398696487512919
Forget Token Entropy: 0.956934777844524
Forget Cosine Similarity: 0.8976136535778642
Forget Entailment Score: 0.56
Model Utility Retain: 0.7329505947748458
Model Utility: 0.48103076264279826
Forget Efficacy: 0.32850878320563703
split: forget05
forget_loss: NPO1+GD1
forget_coeff: 1.0
regularization_coeff: 1.0
learning_rate: 1e-06
epochs: 3
fix_ref_model: 
mask: True
unlearn_step: last
task_id: 1
unlearn_times: 1
