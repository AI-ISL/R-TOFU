Real Authors ROUGE: 0.6708333333333333
Real Authors Probability: 0.2964593318019557
Real Authors Truth Ratio: 0.8743961995398476
Real Authors Token Entropy: 0.9762238840212183
Real Authors Cosine Similarity: 0.8415414126217365
Real Authors Entailment Score: 0.55
Real World ROUGE: 0.7998575498575499
Real World Probability: 0.08579760980324054
Real World Truth Ratio: 0.5483478694921717
Real World Token Entropy: 0.9411127122075243
Real World Cosine Similarity: 0.8377876179213197
Real World Entailment Score: 0.47863247863247865
Retain ROUGE: 0.7229508483329709
Retain Probability: 0.9993886684195634
Retain Truth Ratio: 0.4666582638876802
Retain Token Entropy: 0.958571258941779
Retain Cosine Similarity: 0.904028784284989
Retain Entailment Score: 0.58
Forget ROUGE: 0.612910799390734
Forget Probability: 0.26865242616276713
Forget Truth Ratio: 0.9397957422116084
Forget Token Entropy: 0.9534929373420326
Forget Cosine Similarity: 0.8642526433616876
Forget Entailment Score: 0.425
Model Utility Retain: 0.7142649671201667
Model Utility: 0.47983050332967303
Forget Efficacy: 0.37787767777464065
split: forget05
forget_loss: NPO1+GD1
forget_coeff: 1.0
regularization_coeff: 1.0
learning_rate: 2e-06
epochs: 3
fix_ref_model: 
mask: True
unlearn_step: last
task_id: 1
unlearn_times: 1
