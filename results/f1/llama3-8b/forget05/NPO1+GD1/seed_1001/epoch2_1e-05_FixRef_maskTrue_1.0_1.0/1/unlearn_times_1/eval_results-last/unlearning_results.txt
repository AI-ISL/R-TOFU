Real Authors ROUGE: 0.6963333333333332
Real Authors Probability: 0.3316606911780198
Real Authors Truth Ratio: 0.8780662501081206
Real Authors Token Entropy: 0.9701121010015757
Real Authors Cosine Similarity: 0.8259184611961246
Real Authors Entailment Score: 0.48
Real World ROUGE: 0.8062678062678063
Real World Probability: 0.09263124381991757
Real World Truth Ratio: 0.5455986742852084
Real World Token Entropy: 0.9536054363850215
Real World Cosine Similarity: 0.8405443063149085
Real World Entailment Score: 0.452991452991453
Retain ROUGE: 0.4458353059975815
Retain Probability: 0.8081574000930785
Retain Truth Ratio: 0.44978153686287653
Retain Token Entropy: 0.9357292201765388
Retain Cosine Similarity: 0.7600368472437063
Retain Entailment Score: 0.26666666666666666
Forget ROUGE: 0.4329006228059085
Forget Probability: 0.17054897180583492
Forget Truth Ratio: 0.9306474511619443
Forget Token Entropy: 0.9502180035842749
Forget Cosine Similarity: 0.7570823166891932
Forget Entailment Score: 0.195
Model Utility Retain: 0.5068391206684625
Model Utility: 0.4492406651791728
Forget Efficacy: 0.5027641275074239
split: forget05
forget_loss: NPO1+GD1
forget_coeff: 1.0
regularization_coeff: 1.0
learning_rate: 1e-05
epochs: 2
fix_ref_model: 
mask: True
unlearn_step: last
task_id: 1
unlearn_times: 1
