Real Authors ROUGE: 0.6558333333333334
Real Authors Probability: 0.29833667122306956
Real Authors Truth Ratio: 0.8739895992687411
Real Authors Token Entropy: 0.9746702224623182
Real Authors Cosine Similarity: 0.8223737517185509
Real Authors Entailment Score: 0.53
Real World ROUGE: 0.7884615384615384
Real World Probability: 0.08698433540003005
Real World Truth Ratio: 0.5512893754272901
Real World Token Entropy: 0.9605533110789467
Real World Cosine Similarity: 0.859251009602832
Real World Entailment Score: 0.5384615384615384
Retain ROUGE: 0.7473056855247565
Retain Probability: 0.9994250763157799
Retain Truth Ratio: 0.46564156047372224
Retain Token Entropy: 0.9552599801832813
Retain Cosine Similarity: 0.9059770306448142
Retain Entailment Score: 0.6233333333333333
Forget ROUGE: 0.717858443731427
Forget Probability: 0.2771505831879512
Forget Truth Ratio: 0.9393880638201804
Forget Token Entropy: 0.9608465105328103
Forget Cosine Similarity: 0.9122313383221626
Forget Entailment Score: 0.585
Model Utility Retain: 0.7280506709124334
Model Utility: 0.4860741153286166
Forget Efficacy: 0.3136743141876558
split: forget05
forget_loss: NPO1+GD1
forget_coeff: 1.0
regularization_coeff: 1.0
learning_rate: 1e-06
epochs: 2
fix_ref_model: 
mask: True
unlearn_step: last
task_id: 1
unlearn_times: 1
