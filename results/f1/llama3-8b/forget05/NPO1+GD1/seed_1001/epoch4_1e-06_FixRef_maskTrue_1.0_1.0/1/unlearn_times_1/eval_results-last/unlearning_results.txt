Real Authors ROUGE: 0.6655
Real Authors Probability: 0.29617872032905607
Real Authors Truth Ratio: 0.8743817227040072
Real Authors Token Entropy: 0.9836015086721918
Real Authors Cosine Similarity: 0.8312450957298279
Real Authors Entailment Score: 0.46
Real World ROUGE: 0.8048433048433048
Real World Probability: 0.08631245408397903
Real World Truth Ratio: 0.5493194958625085
Real World Token Entropy: 0.9535032828887812
Real World Cosine Similarity: 0.8475675560916082
Real World Entailment Score: 0.5042735042735043
Retain ROUGE: 0.742438274997542
Retain Probability: 0.999423633937142
Retain Truth Ratio: 0.46599032270846485
Retain Token Entropy: 0.9605910649575417
Retain Cosine Similarity: 0.9098361048599084
Retain Entailment Score: 0.6133333333333333
Forget ROUGE: 0.67264391571688
Forget Probability: 0.27459842978912063
Forget Truth Ratio: 0.9390067770771199
Forget Token Entropy: 0.9603507580809065
Forget Cosine Similarity: 0.8918867671489715
Forget Entailment Score: 0.51
Model Utility Retain: 0.7260391755865564
Model Utility: 0.47948038903897644
Forget Efficacy: 0.34237282205358155
split: forget05
forget_loss: NPO1+GD1
forget_coeff: 1.0
regularization_coeff: 1.0
learning_rate: 1e-06
epochs: 4
fix_ref_model: 
mask: True
unlearn_step: last
task_id: 1
unlearn_times: 1
