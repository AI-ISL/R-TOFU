Real Authors ROUGE: 0.003333333333333333
Real Authors Probability: 0.42276043192301005
Real Authors Truth Ratio: 0.8647014798548593
Real Authors Token Entropy: 0.30259530758539865
Real Authors Cosine Similarity: 0.05568746174685657
Real Authors Entailment Score: 0.0
Real World ROUGE: 0.021367521367521368
Real World Probability: 0.1373744310979408
Real World Truth Ratio: 0.5700706350918407
Real World Token Entropy: 0.29584689093052063
Real World Cosine Similarity: 0.03808881948566717
Real World Entailment Score: 0.017094017094017096
Retain ROUGE: 0.02620668769544474
Retain Probability: 0.7571969472888918
Retain Truth Ratio: 0.3597753548889108
Retain Token Entropy: 0.4400061045882727
Retain Cosine Similarity: 0.12668423453345895
Retain Entailment Score: 0.006666666666666667
Forget ROUGE: 0.023953344928923134
Forget Probability: 0.32620089843735994
Forget Truth Ratio: 0.9050024287465713
Forget Token Entropy: 0.4562717623547395
Forget Cosine Similarity: 0.12306743372231722
Forget Entailment Score: 0.0
Model Utility Retain: 0.029640650209808165
Model Utility: 0.0
Forget Efficacy: 0.7243551788329656
split: forget05
forget_loss: IDK1+GD1
forget_coeff: 1.0
regularization_coeff: 1.0
learning_rate: 1e-05
epochs: 2
fix_ref_model: 
mask: True
unlearn_step: last
task_id: 1
unlearn_times: 1
