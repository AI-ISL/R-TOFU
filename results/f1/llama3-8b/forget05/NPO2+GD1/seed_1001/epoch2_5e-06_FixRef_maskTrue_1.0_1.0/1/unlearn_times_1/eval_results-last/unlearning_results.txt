Real Authors ROUGE: 0.6775
Real Authors Probability: 0.2818963293145644
Real Authors Truth Ratio: 0.870390897200644
Real Authors Token Entropy: 0.9800288165751871
Real Authors Cosine Similarity: 0.8150594753026962
Real Authors Entailment Score: 0.46
Real World ROUGE: 0.8319088319088319
Real World Probability: 0.08337204983211176
Real World Truth Ratio: 0.5468569782423117
Real World Token Entropy: 0.9385642875825789
Real World Cosine Similarity: 0.8404808751203947
Real World Entailment Score: 0.46153846153846156
Retain ROUGE: 0.666089213543805
Retain Probability: 0.9450995210779289
Retain Truth Ratio: 0.46677250777366114
Retain Token Entropy: 0.9478986989697542
Retain Cosine Similarity: 0.8677696165939172
Retain Entailment Score: 0.4266666666666667
Forget ROUGE: 0.5878519948573477
Forget Probability: 0.2183990490742497
Forget Truth Ratio: 0.9376831757030836
Forget Token Entropy: 0.9536357634855173
Forget Cosine Similarity: 0.8484745590388775
Forget Entailment Score: 0.465
Model Utility Retain: 0.6484484415119844
Model Utility: 0.45809206524970364
Forget Efficacy: 0.38851824426528836
split: forget05
forget_loss: NPO2+GD1
forget_coeff: 1.0
regularization_coeff: 1.0
learning_rate: 5e-06
epochs: 2
fix_ref_model: 
mask: True
unlearn_step: last
task_id: 1
unlearn_times: 1
