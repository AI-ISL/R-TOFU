Real Authors ROUGE: 0.6478333333333333
Real Authors Probability: 0.2967866599696404
Real Authors Truth Ratio: 0.8741969334333014
Real Authors Token Entropy: 0.9734934441399693
Real Authors Cosine Similarity: 0.8221731235459447
Real Authors Entailment Score: 0.48
Real World ROUGE: 0.8012820512820513
Real World Probability: 0.08627292676593831
Real World Truth Ratio: 0.5519201329505925
Real World Token Entropy: 0.9432422053088538
Real World Cosine Similarity: 0.8441964999223367
Real World Entailment Score: 0.452991452991453
Retain ROUGE: 0.7515148473284412
Retain Probability: 0.9994089218460916
Retain Truth Ratio: 0.4659308385072173
Retain Token Entropy: 0.9605223294187984
Retain Cosine Similarity: 0.91386908441782
Retain Entailment Score: 0.6366666666666667
Forget ROUGE: 0.7399070845904439
Forget Probability: 0.2745889894218985
Forget Truth Ratio: 0.939423672053772
Forget Token Entropy: 0.9577864989720459
Forget Cosine Similarity: 0.9177501451224088
Forget Entailment Score: 0.595
Model Utility Retain: 0.7331819170701277
Model Utility: 0.4778268098567025
Forget Efficacy: 0.3066660217622955
split: forget05
forget_loss: NPO2+GD1
forget_coeff: 1.0
regularization_coeff: 1.0
learning_rate: 2e-06
epochs: 1
fix_ref_model: 
mask: True
unlearn_step: last
task_id: 1
unlearn_times: 1
