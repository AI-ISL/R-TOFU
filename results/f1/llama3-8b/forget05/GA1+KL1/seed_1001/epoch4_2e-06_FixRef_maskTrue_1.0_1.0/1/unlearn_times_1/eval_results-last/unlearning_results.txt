Real Authors ROUGE: 0.6058333333333333
Real Authors Probability: 0.2852423708457596
Real Authors Truth Ratio: 0.8716956152479709
Real Authors Token Entropy: 0.9721886328235045
Real Authors Cosine Similarity: 0.806563529074192
Real Authors Entailment Score: 0.44
Real World ROUGE: 0.7991452991452992
Real World Probability: 0.08280240557002416
Real World Truth Ratio: 0.5450611998212388
Real World Token Entropy: 0.9662014718807445
Real World Cosine Similarity: 0.8523448496802241
Real World Entailment Score: 0.47863247863247865
Retain ROUGE: 0.6288294215219637
Retain Probability: 0.9992843101716166
Retain Truth Ratio: 0.4686940518336449
Retain Token Entropy: 0.95649330643584
Retain Cosine Similarity: 0.8672321677704652
Retain Entailment Score: 0.47
Forget ROUGE: 0.5416800196808745
Forget Probability: 0.24506324032968282
Forget Truth Ratio: 0.9402981524253408
Forget Token Entropy: 0.9524490115513216
Forget Cosine Similarity: 0.8248658623825759
Forget Entailment Score: 0.36
Model Utility Retain: 0.6629248588219832
Model Utility: 0.4573635727098025
Forget Efficacy: 0.41761854503630524
split: forget05
forget_loss: GA1+KL1
forget_coeff: 1.0
regularization_coeff: 1.0
learning_rate: 2e-06
epochs: 4
fix_ref_model: 
mask: True
unlearn_step: last
task_id: 1
unlearn_times: 1
