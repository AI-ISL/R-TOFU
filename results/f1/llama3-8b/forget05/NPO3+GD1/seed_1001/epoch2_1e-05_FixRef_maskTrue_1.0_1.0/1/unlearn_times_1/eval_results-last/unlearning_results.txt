Real Authors ROUGE: 0.39233333333333337
Real Authors Probability: 0.11070670249510534
Real Authors Truth Ratio: 0.8035795918908069
Real Authors Token Entropy: 0.32361570602211226
Real Authors Cosine Similarity: 0.45635117416270077
Real Authors Entailment Score: 0.41
Real World ROUGE: 0.48034188034188036
Real World Probability: 0.028824281848906175
Real World Truth Ratio: 0.46318976608451184
Real World Token Entropy: 0.29795626747644116
Real World Cosine Similarity: 0.4219744138371868
Real World Entailment Score: 0.5128205128205128
Retain ROUGE: 0.3182086120241481
Retain Probability: 0.039694154196834905
Retain Truth Ratio: 0.43595633001206596
Retain Token Entropy: 0.2766293707947619
Retain Cosine Similarity: 0.41090756106035164
Retain Entailment Score: 0.5966666666666667
Forget ROUGE: 0.29220186139275856
Forget Probability: 0.00815882157694957
Forget Truth Ratio: 0.9008254336836443
Forget Token Entropy: 0.27102034365386724
Forget Cosine Similarity: 0.37557758669834584
Forget Entailment Score: 0.54
Model Utility Retain: 0.15643908397019793
Model Utility: 0.17060006186510077
Forget Efficacy: 0.5766472593296603
split: forget05
forget_loss: NPO3+GD1
forget_coeff: 1.0
regularization_coeff: 1.0
learning_rate: 1e-05
epochs: 2
fix_ref_model: 
mask: True
unlearn_step: last
task_id: 1
unlearn_times: 1
