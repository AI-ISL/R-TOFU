Real Authors ROUGE: 0.6425
Real Authors Probability: 0.27970182167610885
Real Authors Truth Ratio: 0.8718894033864905
Real Authors Token Entropy: 0.9814896605252088
Real Authors Cosine Similarity: 0.8388389313220977
Real Authors Entailment Score: 0.51
Real World ROUGE: 0.7863247863247863
Real World Probability: 0.08220084602063145
Real World Truth Ratio: 0.5492827048353892
Real World Token Entropy: 0.961639253231689
Real World Cosine Similarity: 0.8531459585214273
Real World Entailment Score: 0.5299145299145299
Retain ROUGE: 0.748936421936429
Retain Probability: 0.9994314620780251
Retain Truth Ratio: 0.4719226924965267
Retain Token Entropy: 0.9610349958180014
Retain Cosine Similarity: 0.9075170147418976
Retain Entailment Score: 0.5866666666666667
Forget ROUGE: 0.731495466071753
Forget Probability: 0.2611360879981408
Forget Truth Ratio: 0.9411283464259936
Forget Token Entropy: 0.958720920725409
Forget Cosine Similarity: 0.9124543644487858
Forget Entailment Score: 0.59
Model Utility Retain: 0.7227361501486084
Model Utility: 0.4723308151711691
Forget Efficacy: 0.3127571470110654
split: forget05
forget_loss: NPO3+GD1
forget_coeff: 1.0
regularization_coeff: 1.0
learning_rate: 1e-06
epochs: 3
fix_ref_model: 
mask: True
unlearn_step: last
task_id: 1
unlearn_times: 1
