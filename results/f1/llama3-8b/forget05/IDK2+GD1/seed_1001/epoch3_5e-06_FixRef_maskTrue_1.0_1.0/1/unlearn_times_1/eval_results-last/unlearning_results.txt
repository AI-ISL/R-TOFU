Real Authors ROUGE: 0.1703333333333333
Real Authors Probability: 0.5245268378828615
Real Authors Truth Ratio: 0.8846552368755916
Real Authors Token Entropy: 0.8644189153811185
Real Authors Cosine Similarity: 0.22393544001504778
Real Authors Entailment Score: 0.14
Real World ROUGE: 0.5754985754985755
Real World Probability: 0.17655908712360946
Real World Truth Ratio: 0.5776581351477611
Real World Token Entropy: 0.9553399274499873
Real World Cosine Similarity: 0.6362762326995531
Real World Entailment Score: 0.4358974358974359
Retain ROUGE: 0.027472962929888472
Retain Probability: 0.7475807196343038
Retain Truth Ratio: 0.38729763131820827
Retain Token Entropy: 0.9598121178511358
Retain Cosine Similarity: 0.08952239809868236
Retain Entailment Score: 0.02666666666666667
Forget ROUGE: 0.01746175120351288
Forget Probability: 0.32145599977582223
Forget Truth Ratio: 0.918391922632803
Forget Token Entropy: 0.9486320459041195
Forget Cosine Similarity: 0.07635565214790403
Forget Entailment Score: 0.01
Model Utility Retain: 0.06664347157257695
Model Utility: 0.14314184307801397
Forget Efficacy: 0.7312669348479915
split: forget05
forget_loss: IDK2+GD1
forget_coeff: 1.0
regularization_coeff: 1.0
learning_rate: 5e-06
epochs: 3
fix_ref_model: 
mask: True
unlearn_step: last
task_id: 1
unlearn_times: 1
