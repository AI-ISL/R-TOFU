Real Authors ROUGE: 0.5616666666666668
Real Authors Probability: 0.48136295769499154
Real Authors Truth Ratio: 0.8900770589469879
Real Authors Token Entropy: 0.9470720225985646
Real Authors Cosine Similarity: 0.7555669177696109
Real Authors Entailment Score: 0.54
Real World ROUGE: 0.7834757834757834
Real World Probability: 0.14867098372057552
Real World Truth Ratio: 0.580130110181007
Real World Token Entropy: 0.9563723948357669
Real World Cosine Similarity: 0.8337281359057142
Real World Entailment Score: 0.5641025641025641
Retain ROUGE: 0.5329621678190745
Retain Probability: 0.9344689579828671
Retain Truth Ratio: 0.4081214808724704
Retain Token Entropy: 0.9705230442575856
Retain Cosine Similarity: 0.7912872242741287
Retain Entailment Score: 0.5833333333333334
Forget ROUGE: 0.39662781565944455
Forget Probability: 0.3516256437405047
Forget Truth Ratio: 0.9268522217713178
Forget Token Entropy: 0.9710042054121034
Forget Cosine Similarity: 0.6467015397455543
Forget Entailment Score: 0.2
Model Utility Retain: 0.6379514313593104
Model Utility: 0.5562104096644884
Forget Efficacy: 0.49563855581663563
split: forget05
forget_loss: IDK2+GD1
forget_coeff: 1.0
regularization_coeff: 1.0
learning_rate: 5e-06
epochs: 2
fix_ref_model: 
mask: True
unlearn_step: last
task_id: 1
unlearn_times: 1
